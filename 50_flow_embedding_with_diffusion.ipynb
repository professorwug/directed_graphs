{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp diffusion_flow_embedding\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Embedding with Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first generation of the flow embedding network was based around the preservation of distances in the embedding space. It's now obvious that this was the wrong tact. Caring about distance preservation puts most emphasis on far away points (including pathological cases, when there's no connectivity and the distance is \"infinite\"). \n",
    "\n",
    "Affinities do the trick here much better. They naturally emphasize only local distances, and allow the network to heavily discount (if not outright ignore) long-range connectivity. \n",
    "\n",
    "This locality creates a new model of flow. Previously, our network used euclidean lines between points, and used the flow only to determine the length of each line. Going against (and especially, going perpendicular) to the flow was *possible*, just not easy.\n",
    "\n",
    "With the diffusion-based model, we think in terms of probabilities, rather than distances. \n",
    "This has a couple of downstream effects:\n",
    "- Going with the flow is *highly* encouraged. Going against or even perpendicular is given (depending on the kernel function used) a probability close to zero.\n",
    "- Points travel on *paths* dictated by the flow. The likelihood of reaching point $i$ from $j$ is governed not by the *shortest* path, but the aggregate of all paths, weighted by probability. This has the dual effects of diminishing the effect of outliers, and providing an intuitive model of motion. You don't have to reason about which path is \"lowest energy\", just which path is most likely based on the directions of flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pieces of the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the probabilities of transition between the points with three steps:\n",
    "1. Learn a \"Flow Artist\": a neural network to learn flow over the euclidean field.\n",
    "  - This is currently a function of two variables $F(x,y): \\mathbb{R}^2 \\to \\mathbb{R}$. The direction of flow is the negative gradient $-\\Delta F$.\n",
    "2. Compute the probabilities of transition between the grid points and the embeddings of points.\n",
    "3. Compute the probabilities of transition from grid points to grid points.\n",
    "\n",
    "The probability of transitioning from one point to another is then the amalgam of these steps: we transition to the grid, transition within the grid for $t$ steps, and then transition back to a point. Each probability gives a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Kernel from Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foundation of these is the conversion from *flow* (the vector field) to probabilities of transition. This is done using a kernel based on the degree of divergence between the direction specified and the flow, as below, where $r$ is the flow direction (a vector) and $v$ is the direction of the edge.\n",
    "$$ e^{-(\\|r\\|^2 - r \\cdot v)/\\sigma} $$\n",
    "When the flow is aligned with the direction, this returns 1. When it is perpendicular, $e^{-\\|r\\|^2/\\sigma}$, and when against the flow, $e^{-2\\|r\\|^2/\\sigma}$.\n",
    "\n",
    "We should tune $\\sigma$ to ensure that a 45 degree angle returns a quantity significantly above zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a function that performs this operation on batches of flows and directions. The input will be an array of flows (e.g. the flow per point), and a batch of directions (e.g. NESW for each point). It will, of course, use PyTorch for backpropogation capable operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affinity_from_flow(flows, directions_array, sigma=1):\n",
    "  \"\"\"Compute probabilities of transition in the given directions based on the flow. \n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  flows : torch tensor of shape n_points x n_dims\n",
    "      _description_\n",
    "  directions_array : torch tensor of shape n_directions x n_points x n_dims. Assumed to be normalized.\n",
    "      _description_\n",
    "  sigma : int, optional\n",
    "      kernel bandwidth, by default 1\n",
    "  returns (n_points)\n",
    "  \"\"\"\n",
    "  assert len(flows.shape) == 2 # flows should only have one dimension\n",
    "  assert len(directions_array.shape) > 1 and len(directions_array.shape) < 4\n",
    "  n_directions = directions_array.shape[0]\n",
    "  # TODO: Normalize directions\n",
    "  # directions_array /= torch.linalg.norm(directions_array,dim=-1)\n",
    "  if len(directions_array) == 1: # convert to 2d array if necessary\n",
    "    directions_array = directions_array[:,None] \n",
    "  # compute dot products as matrix multiplication\n",
    "  dot_products = (directions_array * flows).sum(-1)\n",
    "  # take distance between flow projected onto direction and the direction\n",
    "  distance_from_flow = (torch.linalg.norm(flows,dim=1)**2).repeat(n_directions,1) - dot_products\n",
    "  # put the points on rows, directions in columns\n",
    "  distance_from_flow = distance_from_flow.T\n",
    "  # take kernel of distances\n",
    "  kernel =  torch.exp(-distance_from_flow/sigma)\n",
    "  # normalize kernel\n",
    "  # kernel /= torch.sum(kernel,axis=1)\n",
    "  return kernel\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Sample Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = torch.rand(4,2) # Flows for each of 4 points\n",
    "directions_array = torch.rand(7,4,2) # 7 directions, for each of the four points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, take a dot product between the directions and the flow, to get a strength of flow at each point in each direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_products = (directions_array * flows).sum(-1)\n",
    "dot_products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert these dot products into distances by subtracting the norm squared of the flows from the dot product with the flow. If exactly with the flow, we get zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8590e-05,  2.1581e-01,  6.1518e-02, -8.1743e-02],\n",
       "        [-1.3722e-02, -1.2842e-01,  2.4325e-01, -9.5438e-02],\n",
       "        [-7.7041e-02,  1.8273e-02,  4.8354e-01,  7.4008e-02],\n",
       "        [-2.9780e-03, -2.8017e-01,  2.8681e-01,  5.5978e-02],\n",
       "        [-5.1044e-02, -6.0007e-02, -2.4478e-01, -3.0974e-01],\n",
       "        [-7.4572e-03,  1.9018e-01,  5.1931e-02,  2.3689e-01],\n",
       "        [-6.2452e-02, -1.1898e-01,  5.1483e-01,  2.2691e-01]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_from_flow = (torch.linalg.norm(flows,dim=1)**2).repeat(7,1) - dot_products\n",
    "distance_from_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure this is working as expected, we'll try computations on a single sample point, with flow going in direction (1,1). We'll compare this with six directions: one with, one against, and the rest in the shape of a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = torch.tensor([[1,1]]).float()\n",
    "directions = torch.tensor([\n",
    "  [[0.7,0.7]],\n",
    "  [[0,1]],\n",
    "  [[1,0]],\n",
    "  [[0,-1]],\n",
    "  [[-1,0]],\n",
    "  [[-0.7,-0.7]]\n",
    "]).float()\n",
    "probs = affinity_from_flow(flow,directions,sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3012, 0.1353, 0.1353, 0.0025, 0.0025, 0.0011]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this went according to plan, the direction with the flow should have probability 1, and the one against should have probability near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16b00c550>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma=0.5$ works well here. In particular, the 45 degree angles have fairly high probability, while still being less than the probability of going straight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Transition Probabilities Between a Grid and Points, and Vice Versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next functions will take three inputs: a set of points, a grid, and flows at each point and each point on the grid. It is tasked with returning three matrices: a transition matrix between the points and the grid, a transition matrix between the grid and the points, and the transition matrix from the grid to the grid.\n",
    "\n",
    "These tasks should be separated, as each is called in different circumstances.\n",
    "- The grid-to-point (and vv) function will be called each time the points are moved, or the grid is updated, or the flow is updated.\n",
    "- The grid-to-grid function will be called whenever the grid is updated, or the flow is updated.\n",
    "\n",
    "Both can be encapsulated in the same function, which computes an affinity matrix from pointset 1 to pointset 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic of the functions: \n",
    "1. For each point in set 1, sort the points in set 2 by distance.\n",
    "2. Choose the $n$ nearest neighbors (optional computational boost), and compute the transition probabilities to them, storing the results in the affinity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affinity_matrix_from_pointset_to_pointset(pointset1, pointset2, flows,n_neighbors=None,sigma=0.5):\n",
    "  \"\"\"Compute affinity matrix between the points of pointset1 and pointset2, using the provided flow.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  pointset1 : torch tensor, n1 x d\n",
    "      The first pointset, to calculate affinities *from*\n",
    "  pointset2 : torch tensor, n2 x d\n",
    "      The second pointset, to calculate affinities *to* (from pointset1)\n",
    "  flow : a function that, when called at a point, gives the flow at that point\n",
    "  n_neighbors : number of neighbors to include in affinity computations. All neighbors beyond it are given affinity zero\n",
    "  (currently not implemented)\n",
    "\n",
    "  Returns:\n",
    "  Affinity matrix: torch tensor of shape n1 x n2\n",
    "  \"\"\"\n",
    "  # Calculate the directions from point i in pointset 1 to point j in pointset 2\n",
    "  n1 = pointset1.shape[0]\n",
    "  n2 = pointset2.shape[0]\n",
    "  P2 = pointset2[:,:,None].repeat(1,1,n1)\n",
    "  P1 = pointset1.T.repeat(n2,1,1)\n",
    "  P3 = (P2 - P1)\n",
    "  P3 = P3.transpose(1,2)\n",
    "  # compute affinities from flows and directions\n",
    "  affinities = affinity_from_flow(flows,P3,sigma=sigma)\n",
    "  return affinities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of how the function should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointset1 = torch.rand(4,2)\n",
    "pointset2 = torch.rand(7,2)\n",
    "def flow(x):\n",
    "  return x**2/torch.linalg.norm(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4344, 0.1508],\n",
       "        [0.0742, 0.4641],\n",
       "        [0.3145, 0.1668],\n",
       "        [0.1335, 0.0274]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9777, 0.6445],\n",
       "        [0.6751, 0.2807],\n",
       "        [0.2593, 0.2520],\n",
       "        [0.2394, 0.7767],\n",
       "        [0.5078, 0.2929],\n",
       "        [0.4219, 0.8428],\n",
       "        [0.2307, 0.3603]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9777, 0.9777, 0.9777, 0.9777],\n",
       "         [0.6445, 0.6445, 0.6445, 0.6445]],\n",
       "\n",
       "        [[0.6751, 0.6751, 0.6751, 0.6751],\n",
       "         [0.2807, 0.2807, 0.2807, 0.2807]],\n",
       "\n",
       "        [[0.2593, 0.2593, 0.2593, 0.2593],\n",
       "         [0.2520, 0.2520, 0.2520, 0.2520]],\n",
       "\n",
       "        [[0.2394, 0.2394, 0.2394, 0.2394],\n",
       "         [0.7767, 0.7767, 0.7767, 0.7767]],\n",
       "\n",
       "        [[0.5078, 0.5078, 0.5078, 0.5078],\n",
       "         [0.2929, 0.2929, 0.2929, 0.2929]],\n",
       "\n",
       "        [[0.4219, 0.4219, 0.4219, 0.4219],\n",
       "         [0.8428, 0.8428, 0.8428, 0.8428]],\n",
       "\n",
       "        [[0.2307, 0.2307, 0.2307, 0.2307],\n",
       "         [0.3603, 0.3603, 0.3603, 0.3603]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2 = pointset2[:,:,None].repeat(1,1,4)\n",
    "P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]],\n",
       "\n",
       "        [[0.4344, 0.0742, 0.3145, 0.1335],\n",
       "         [0.1508, 0.4641, 0.1668, 0.0274]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1 = pointset1.T.repeat(7,1,1)\n",
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5433,  0.9035,  0.6632,  0.8442],\n",
       "         [ 0.4937,  0.1804,  0.4777,  0.6171]],\n",
       "\n",
       "        [[ 0.2407,  0.6009,  0.3607,  0.5417],\n",
       "         [ 0.1299, -0.1834,  0.1139,  0.2533]],\n",
       "\n",
       "        [[-0.1751,  0.1851, -0.0552,  0.1258],\n",
       "         [ 0.1012, -0.2121,  0.0852,  0.2246]],\n",
       "\n",
       "        [[-0.1950,  0.1652, -0.0750,  0.1060],\n",
       "         [ 0.6259,  0.3126,  0.6099,  0.7493]],\n",
       "\n",
       "        [[ 0.0734,  0.4336,  0.1933,  0.3743],\n",
       "         [ 0.1422, -0.1711,  0.1262,  0.2655]],\n",
       "\n",
       "        [[-0.0125,  0.3477,  0.1075,  0.2885],\n",
       "         [ 0.6920,  0.3787,  0.6760,  0.8154]],\n",
       "\n",
       "        [[-0.2037,  0.1565, -0.0837,  0.0973],\n",
       "         [ 0.2095, -0.1038,  0.1935,  0.3329]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3 = (P2-P1)\n",
    "P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5433,  0.4937],\n",
       "         [ 0.9035,  0.1804],\n",
       "         [ 0.6632,  0.4777],\n",
       "         [ 0.8442,  0.6171]],\n",
       "\n",
       "        [[ 0.2407,  0.1299],\n",
       "         [ 0.6009, -0.1834],\n",
       "         [ 0.3607,  0.1139],\n",
       "         [ 0.5417,  0.2533]],\n",
       "\n",
       "        [[-0.1751,  0.1012],\n",
       "         [ 0.1851, -0.2121],\n",
       "         [-0.0552,  0.0852],\n",
       "         [ 0.1258,  0.2246]],\n",
       "\n",
       "        [[-0.1950,  0.6259],\n",
       "         [ 0.1652,  0.3126],\n",
       "         [-0.0750,  0.6099],\n",
       "         [ 0.1060,  0.7493]],\n",
       "\n",
       "        [[ 0.0734,  0.1422],\n",
       "         [ 0.4336, -0.1711],\n",
       "         [ 0.1933,  0.1262],\n",
       "         [ 0.3743,  0.2655]],\n",
       "\n",
       "        [[-0.0125,  0.6920],\n",
       "         [ 0.3477,  0.3787],\n",
       "         [ 0.1075,  0.6760],\n",
       "         [ 0.2885,  0.8154]],\n",
       "\n",
       "        [[-0.2037,  0.2095],\n",
       "         [ 0.1565, -0.1038],\n",
       "         [-0.0837,  0.1935],\n",
       "         [ 0.0973,  0.3329]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3 = P3.transpose(1,2)\n",
    "P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6175, 0.0744],\n",
       "        [0.0180, 0.7046],\n",
       "        [0.3236, 0.0910],\n",
       "        [0.0583, 0.0025]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows = flow(pointset1)\n",
    "flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = affinity_from_flow(flows,P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3722,  0.1434,  0.2581,  0.0507],\n",
       "        [ 0.1583, -0.1184,  0.1271,  0.0322],\n",
       "        [-0.1006, -0.1461, -0.0101,  0.0079],\n",
       "        [-0.0738,  0.2232,  0.0312,  0.0080],\n",
       "        [ 0.0559, -0.1128,  0.0740,  0.0225],\n",
       "        [ 0.0438,  0.2731,  0.0963,  0.0188],\n",
       "        [-0.1102, -0.0703, -0.0095,  0.0065]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P3 * flows).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6219, 0.7049, 0.3361, 0.0583],\n",
       "        [0.6219, 0.7049, 0.3361, 0.0583],\n",
       "        [0.6219, 0.7049, 0.3361, 0.0583],\n",
       "        [0.6219, 0.7049, 0.3361, 0.0583]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.norm(flows,dim=1).repeat(4,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointset1 = torch.rand(4,2)\n",
    "pointset2 = torch.rand(7,2)\n",
    "def flow(x):\n",
    "  return 5*x**2 - 3*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb Cell 44'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000043?line=0'>1</a>\u001b[0m P \u001b[39m=\u001b[39m affinity_matrix_from_pointset_to_pointset(pointset1,pointset2,flow)\n",
      "\u001b[1;32m/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb Cell 27'\u001b[0m in \u001b[0;36maffinity_matrix_from_pointset_to_pointset\u001b[0;34m(pointset1, pointset2, flows, n_neighbors, sigma)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000026?line=23'>24</a>\u001b[0m P3 \u001b[39m=\u001b[39m P3\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000026?line=24'>25</a>\u001b[0m \u001b[39m# compute affinities from flows and directions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000026?line=25'>26</a>\u001b[0m affinities \u001b[39m=\u001b[39m affinity_from_flow(flows,P3,sigma\u001b[39m=\u001b[39;49msigma)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000026?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m affinities\n",
      "\u001b[1;32m/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb Cell 10'\u001b[0m in \u001b[0;36maffinity_from_flow\u001b[0;34m(flows, directions_array, sigma)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maffinity_from_flow\u001b[39m(flows, directions_array, sigma\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=2'>3</a>\u001b[0m   \u001b[39m\"\"\"Compute probabilities of transition in the given directions based on the flow. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=3'>4</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=4'>5</a>\u001b[0m \u001b[39m  Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=12'>13</a>\u001b[0m \u001b[39m  returns (n_points)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=13'>14</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=14'>15</a>\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(flows\u001b[39m.\u001b[39;49mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39m# flows should only have one dimension\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=15'>16</a>\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(directions_array\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(directions_array\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adjourner/Projects/directed_graphs/50_flow_embedding_with_diffusion.ipynb#ch0000009?line=16'>17</a>\u001b[0m   n_directions \u001b[39m=\u001b[39m directions_array\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "P = affinity_matrix_from_pointset_to_pointset(pointset1,pointset2,flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0565e-01, 5.3941e-01, 3.7305e-01, 7.5059e-01, 4.9494e-01, 7.6469e-01,\n",
       "         4.6829e-01],\n",
       "        [1.0087e-03, 1.5339e-03, 3.8199e-03, 4.3500e-04, 2.8768e-03, 3.4997e-04,\n",
       "         2.0823e-03],\n",
       "        [3.8428e-02, 3.5911e-02, 8.2008e-02, 5.1107e-02, 1.5597e-02, 7.4845e-02,\n",
       "         5.4968e-02],\n",
       "        [5.9214e-01, 5.6680e-01, 3.8327e-01, 6.1776e-01, 6.6328e-01, 5.6874e-01,\n",
       "         4.7513e-01]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9966, 0.0121, 0.3529, 3.8671])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1515, 0.1350, 0.0933, 0.1878, 0.1238, 0.1913, 0.1172],\n",
       "        [0.0833, 0.1267, 0.3155, 0.0359, 0.2376, 0.0289, 0.1720],\n",
       "        [0.1089, 0.1018, 0.2324, 0.1448, 0.0442, 0.2121, 0.1558],\n",
       "        [0.1531, 0.1466, 0.0991, 0.1597, 0.1715, 0.1471, 0.1229]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(1/P.sum(axis=1)) @ P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting the pieces together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Loss Function: KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our network used a frobenius norm between matrices as the loss function. Now, it is comparing probability distributions, rather than distance matrices, and so we want something more robust. \n",
    "\n",
    "We'll start by using the simplest possible divergence: the KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.KLDivLoss(reduction = 'batchmean',log_target = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pg = torch.rand(10,10)\n",
    "Pe = torch.rand(10,10)\n",
    "Pg_log = torch.log(Pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5967)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(Pg_log,Pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to put the pieces together, into a `FlowEmbedder` Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from tqdm import trange\n",
    "from directed_graphs.utils import diffusion_matrix_from_graph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DiffusionFlowEmbedder(torch.nn.Module):\n",
    "\tdef __init__(self, X, flows, t = 4, sigma_graph = 0.5, sigma_embedding=0.5, embedding_dimension=2):\n",
    "\t\t\"\"\"Flow Embedding with diffusion\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tX : torch tensor n_points x n_dim\n",
    "\t\t\tdata matrix\n",
    "\t\tflows : torch tensor n_points x n_dim\n",
    "\t\t\tThe flow at each point\n",
    "\t\tt : int\n",
    "\t\t\tLoss is computed with the diffusion operator powered to this number\n",
    "\t\tsigma in [0,1]\n",
    "\t\t\tKernel bandwidth in the embedding\n",
    "\t\t\"\"\"\n",
    "\t\t# initialize parameters\n",
    "\t\tsuper(DiffusionFlowEmbedder, self).__init__()\n",
    "\t\tself.X = X\n",
    "\t\tself.ground_truth_flows = flows\n",
    "\t\tself.t = t\n",
    "\t\tself.sigma_embedding = sigma_embedding\n",
    "\t\tself.sigma_graph = sigma_graph\n",
    "\t\tself.nnodes = X.shape[0]\n",
    "\t\tself.data_dimension = X.shape[1]\n",
    "\t\tself.losses = []\n",
    "\t\tself.embedding_dimension = embedding_dimension\n",
    "\t\t# Compute P^t of the graph, the powered diffusion matrix\n",
    "\t\t# TODO: This can be optimized using landmarks, etc. For now it's straight sparse matrix multiplication\n",
    "\t\t# TODO: Migrate to a specialized function for dataset affinity calculation, with automatic kernel bandwidth selection, and the like\n",
    "\t\tself.P_graph = affinity_matrix_from_pointset_to_pointset(X,X,flows,sigma=sigma_graph)\n",
    "\t\tself.P_graph_t = torch.matrix_power(self.P_graph,self.t)\n",
    "\t\t# Flow field\n",
    "\t\tself.FlowArtist = nn.Sequential(nn.Linear(2, 10),\n",
    "\t\t                       nn.Tanh(),\n",
    "\t\t                       nn.Linear(10, 10),\n",
    "\t\t                       nn.Tanh(),\n",
    "\t\t                       nn.Linear(10, 2))\n",
    "\t\t# Autoencoder to embed the points into a low dimension\n",
    "\t\tself.encoder = nn.Sequential(nn.Linear(self.data_dimension, 100),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(100, 10),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(10, self.embedding_dimension))\n",
    "\t\tself.decoder = nn.Sequential(nn.Linear(self.embedding_dimension, 10),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(10, 100),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(100, self.data_dimension))\n",
    "\t\t# training ops\n",
    "\t\tself.KLD = nn.KLDivLoss(reduction='batchmean',log_target=False)\n",
    "\t\tself.MSE = nn.MSELoss()\n",
    "\t\tself.optim = torch.optim.Adam(self.parameters())\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef compute_embedding_P(self):\n",
    "\t\tA = affinity_matrix_from_pointset_to_pointset(self.embedded_points,self.embedded_points,flows = self.FlowArtist(self.embedded_points), sigma = self.sigma_embedding)\n",
    "\t\t# flow\n",
    "\t\tself.P_embedding = torch.diag(1/A.sum(axis=1)) @ A\n",
    "\t\t# power it\n",
    "\t\tself.P_embedding_t = torch.matrix_power(self.P_embedding,self.t)\n",
    "\n",
    "\tdef loss(self):\n",
    "\t\tself.embedded_points = self.encoder(self.X)\n",
    "\t\t# compute embedding diffusion matrix\n",
    "\t\tself.compute_embedding_P()\n",
    "\t\t# compute autoencoder loss\n",
    "\t\tX_reconstructed = self.decoder(self.embedded_points)\n",
    "\t\treconstruction_loss = self.MSE(X_reconstructed, self.X)\n",
    "\t\t# take KL divergence between it and actual P\n",
    "\t\tlog_P_embedding_t = torch.log(self.P_embedding_t)\n",
    "\t\tdiffusion_loss = self.KLD(log_P_embedding_t.to_dense(),self.P_graph_t.to_dense())\n",
    "\t\tcost = diffusion_loss + reconstruction_loss\n",
    "\t\t# print(f\"cost is KLD {diffusion_loss} with recon {reconstruction_loss}\")\n",
    "\t\tself.losses.append([diffusion_loss,reconstruction_loss])\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef visualize_points(self, labels):\n",
    "\t\t# controls the x and y axes of the plot\n",
    "\t\t# linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)\n",
    "\t\tminx = min(self.embedded_points[:,0].detach().numpy())-1\n",
    "\t\tmaxx = max(self.embedded_points[:,0].detach().numpy())+1\n",
    "\t\tminy = min(self.embedded_points[:,1].detach().numpy())-1\n",
    "\t\tmaxy = max(self.embedded_points[:,1].detach().numpy())+1\n",
    "\t\tx, y = np.meshgrid(np.linspace(minx,maxx,20),np.linspace(miny,maxy,20))\n",
    "\t\tx = torch.tensor(x,dtype=float)\n",
    "\t\ty = torch.tensor(y,dtype=float)\n",
    "\t\txy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float()\n",
    "\t\tuv = self.FlowArtist(xy_t).detach()\n",
    "\t\tu = uv[:,:,0]\n",
    "\t\tv = uv[:,:,1]\n",
    "\t\t\n",
    "\t\t# quiver \n",
    "\t\t# \tplots a 2D field of arrows\n",
    "\t\t# \tquiver([X, Y], U, V, [C], **kw); \n",
    "\t\t# \tX, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.\n",
    "\t\t\n",
    "\t\tplt.quiver(x,y,u,v)\n",
    "\t\tsc = plt.scatter(self.embedded_points[:,0].detach(),self.embedded_points[:,1].detach(), c=labels)\n",
    "\t\tplt.legend()\n",
    "\t\t# Display all open figures.\n",
    "\t\tplt.show()\n",
    "\n",
    "\n",
    "\tdef fit(self,n_steps = 1000):\n",
    "\t\t# train Flow Embedder on the provided graph\n",
    "\t\tself.train()\n",
    "\t\tfor step in trange(n_steps):\n",
    "\t\t\tself.optim.zero_grad()\n",
    "\t\t\t# compute loss\n",
    "\t\t\tloss = self.loss()\n",
    "\t\t\t# print(\"loss is \",loss)\n",
    "\t\t\t# compute gradient and step backwards\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optim.step()\n",
    "\t\t\t# TODO: Criteria to automatically end training\n",
    "\t\tprint(\"Exiting training with loss \",loss)\n",
    "\t\treturn self.embedded_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyg_from_source')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

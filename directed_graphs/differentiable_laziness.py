# AUTOGENERATED! DO NOT EDIT! File to edit: 12_differentiable_diffusion_curvature.ipynb (unless otherwise specified).

__all__ = ['curvature', 'diffusion_curvature_of_graph']

# Cell
import torch
from torch import sparse
def curvature(P, diffusion_powers = 8, aperture = 20, smoothing = 1, avg_transition_probabilities = True, precomputed_powered_P = None):
  """Same as the `curvature` function, but uses pytorch as backend instead of numpy.
  Works on both tensors and COO sparse tensors.
  """
  sample_number = 100
  row_partitions = torch.empty(sample_number)
  for idx, i in enumerate(torch.randint(P.shape[0], size = (sample_number,))):
    row_partitions[idx] = torch.topk(P[i].to_dense(), aperture, largest=True, sorted = True)[0][0] # the first [0] gets the values; the second gets the first value
  P_threshold = torch.mean(row_partitions)
  # Compute powers of P
  if precomputed_powered_P is not None:
    P_powered = precomputed_powered_P
  else:
    P_powered = torch.linalg.matrix_power(P, diffusion_powers)
  near_neighbors_only = P_powered * P_threshold
  if near_neighbors_only.is_sparse:
    laziness_aggregate = sparse.sum(near_neighbors_only,dim=[1]).to_dense()
  else:
    laziness_aggregate = torch.sum(near_neighbors_only, dim=1)
  laziness = laziness_aggregate
  if smoothing:
    average_laziness = P @ laziness[:,None]
    average_laziness = average_laziness.squeeze()
    laziness = average_laziness
  return laziness



# Cell
from .utils import diffusion_matrix_from_graph
def diffusion_curvature_of_graph(graph,t=8):
  P = diffusion_matrix_from_graph(G=graph)
  ks = curvature(P, diffusion_powers= t)
  return ks
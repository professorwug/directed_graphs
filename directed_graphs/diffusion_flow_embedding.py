# AUTOGENERATED! DO NOT EDIT! File to edit: 50_flow_embedding_with_diffusion.ipynb (unless otherwise specified).

__all__ = ['affinity_from_flow', 'affinity_matrix_from_pointset_to_pointset', 'DiffusionFlowEmbedder']

# Cell
# hide
import torch

# Cell
def affinity_from_flow(flows, directions_array, sigma=1):
  """Compute probabilities of transition in the given directions based on the flow.

  Parameters
  ----------
  flows : torch tensor of shape n_points x n_dims
      _description_
  directions_array : torch tensor of shape n_directions x n_points x n_dims. Assumed to be normalized.
      _description_
  sigma : int, optional
      kernel bandwidth, by default 1
  returns (n_points)
  """
  assert len(flows.shape) == 2 # flows should only have one dimension
  assert len(directions_array.shape) > 1 and len(directions_array.shape) < 4
  n_directions = directions_array.shape[0]
  # TODO: Normalize directions
  # directions_array /= torch.linalg.norm(directions_array,dim=-1)
  if len(directions_array) == 1: # convert to 2d array if necessary
    directions_array = directions_array[:,None]
  # compute dot products as matrix multiplication
  dot_products = (directions_array * flows).sum(-1)
  # take distance between flow projected onto direction and the direction
  distance_from_flow = (torch.linalg.norm(flows,dim=1)**2).repeat(n_directions,1) - dot_products
  # put the points on rows, directions in columns
  distance_from_flow = distance_from_flow.T
  # take kernel of distances
  kernel =  torch.exp(-distance_from_flow/sigma)
  # normalize kernel
  # kernel /= torch.sum(kernel,axis=1)
  return kernel



# Cell
def affinity_matrix_from_pointset_to_pointset(pointset1, pointset2, flow,n_neighbors=None,sigma=0.5):
  """Compute affinity matrix between the points of pointset1 and pointset2, using the provided flow.

  Parameters
  ----------
  pointset1 : torch tensor, n1 x d
      The first pointset, to calculate affinities *from*
  pointset2 : torch tensor, n2 x d
      The second pointset, to calculate affinities *to* (from pointset1)
  flow : a function that, when called at a point, gives the flow at that point
  n_neighbors : number of neighbors to include in affinity computations. All neighbors beyond it are given affinity zero
  (currently not implemented)

  Returns:
  Affinity matrix: torch tensor of shape n1 x n2
  """
  # Calculate the flows from pointset 1
  flows = flow(pointset1)
  # Calculate the directions from point i in pointset 1 to point j in pointset 2
  n1 = pointset1.shape[0]
  n2 = pointset2.shape[0]
  P2 = pointset2[:,:,None].repeat(1,1,n1)
  P1 = pointset1.T.repeat(n2,1,1)
  P3 = (P2 - P1)
  P3 = P3.transpose(1,2)
  # compute affinities from flows and directions
  affinities = affinity_from_flow(flows,P3,sigma=sigma)
  return affinities


# Cell
import torch
from torch import nn
import torch.nn.functional as F
import torch_geometric
from tqdm import trange
from .utils import diffusion_matrix_from_graph
import numpy as np
import matplotlib.pyplot as plt

class DiffusionFlowEmbedder(torch.nn.Module):
	def __init__(self,graph, t = 4, sigma=0.5):
		"""Flow Embedding with diffusion

		Parameters
		----------
		graph : pyg graph
			a directed graph, to be embedded by the flow embedder, in pytorch geometric data format
		"""
		super(DiffusionFlowEmbedder, self).__init__()
		self.graph = graph
		self.t = t
		self.sigma = 0.5
		self.nnodes = graph.num_nodes
		self.embedding_dimension = 2
		# Compute P^t of the graph, the powered diffusion matrix
		# TODO: This can be optimized using landmarks, etc. For now it's straight sparse matrix multiplication
		self.P_graph = diffusion_matrix_from_graph(G = graph)
		self.P_graph_t = torch.matrix_power(self.P_graph,self.t)
		# Embedding points
		self.embedded_points = nn.Parameter(torch.rand(self.nnodes,2))
		# Flow field
		self.FlowArtist = nn.Sequential(nn.Linear(2, 10),
		                       nn.Tanh(),
		                       nn.Linear(10, 10),
		                       nn.Tanh(),
		                       nn.Linear(10, 2))
		# training ops
		self.KLD = nn.KLDivLoss(reduction='batchmean',log_target=False)
		self.optim = torch.optim.Adam(self.parameters())
									

	def compute_embedding_P(self):
		A = affinity_matrix_from_pointset_to_pointset(self.embedded_points,self.embedded_points,flow = self.FlowArtist, sigma = self.sigma)
		# flow
		self.P_embedding = torch.diag(1/A.sum(axis=1)) @ A
		# power it
		self.P_embedding_t = torch.matrix_power(self.P_embedding,self.t)

	def loss(self):
		# compute embedding diffusion matrix
		self.compute_embedding_P()
		# take KL divergence between it and actual P
		log_P_embedding_t = torch.log(self.P_embedding_t)
		cost = self.KLD(log_P_embedding_t.to_dense(),self.P_graph_t.to_dense())
		return cost
	def visualize_points(self, labels):
		# controls the x and y axes of the plot
		# linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)
		minx = min(self.embedded_points[:,0].detach().numpy())-1
		maxx = max(self.embedded_points[:,0].detach().numpy())+1
		miny = min(self.embedded_points[:,1].detach().numpy())-1
		maxy = max(self.embedded_points[:,1].detach().numpy())+1
		x, y = np.meshgrid(np.linspace(minx,maxx,20),np.linspace(miny,maxy,20))
		x = torch.tensor(x,dtype=float)
		y = torch.tensor(y,dtype=float)
		xy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float()
		uv = self.FlowArtist(xy_t).detach()
		u = uv[:,:,0]
		v = uv[:,:,1]
		"""
		quiver
			plots a 2D field of arrows
			quiver([X, Y], U, V, [C], **kw);
			X, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.
		"""
		plt.quiver(x,y,u,v)
		sc = plt.scatter(self.embedded_points[:,0].detach(),self.embedded_points[:,1].detach(), c=labels)
		plt.legend(handles = sc.legend_elements()[0], title="Blobs", labels=labels)
		"""Display all open figures."""
		plt.show()


	def fit(self,n_steps = 1000):
		# train Flow Embedder on the provided graph
		self.train()
		for step in trange(n_steps):
			self.optim.zero_grad()
			# compute loss
			loss = self.loss()
			# print("loss is ",loss)
			# compute gradient and step backwards
			loss.backward()
			self.optim.step()
		print("Exiting training with loss ",loss)
		return self.embedded_points





{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# default_exp flow_embedding_training_utils\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import directed_graphs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Utils for the Flow Embedder\n",
    "\n",
    "In the quest to have maximum code separation, we're separating the mass of 05c's flow embedder into separate embedding and visualization schemes.\n",
    "\n",
    "This notebook will house barebones code to visualize the losses and embedded points of the MFE concurrently with training, as well as tools for saving and creating GIFs from the embedding trainings.\n",
    "\n",
    "A general philosophy here is to avoid printing ad naseum as much as possible, by compressing the form of information served to the most appropriate condensed form for efficient summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the meat and bones of the flow embedder: visualizing the embedded points, with a grid to visualize flow arrows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from directed_graphs.multiscale_flow_embedder import compute_grid\n",
    "device = torch.device(\"cuda\" if torch.has_cuda else \"cpu\")\n",
    "def visualize_points(embedded_points, flow_artist, labels = None, device = device, title = \"Flow Embedding\", save = False, **kwargs):\n",
    "\t\t# computes grid around points\n",
    "\t\t# TODO: This might create CUDA errors\n",
    "\t\tgrid = compute_grid(embedded_points.to(device)).to(device)\n",
    "\t\t# controls the x and y axes of the plot\n",
    "\t\t# linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)\n",
    "\t\tuv = flow_artist(grid).detach().cpu()\n",
    "\t\tu = uv[:,0].cpu()\n",
    "\t\tv = uv[:,1].cpu()\n",
    "\t\tx = grid.detach().cpu()[:,0]\n",
    "\t\ty = grid.detach().cpu()[:,1]\n",
    "\t\t# quiver \n",
    "\t\t# \tplots a 2D field of arrows\n",
    "\t\t# \tquiver([X, Y], U, V, [C], **kw); \n",
    "\t\t# \tX, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.\n",
    "\t\tif labels is not None:\n",
    "\t\t\tsc = plt.scatter(embedded_points[:,0].detach().cpu(),embedded_points[:,1].detach().cpu(), c=labels)\n",
    "# \t\t\tplt.legend()\n",
    "\t\telse:\n",
    "\t\t\tsc = plt.scatter(embedded_points[:,0].detach().cpu(),embedded_points[:,1].detach().cpu())\n",
    "\t\tplt.suptitle(\"Flow Embedding\")\n",
    "\t\tplt.quiver(x,y,u,v)\n",
    "\t\t# Display all open figures.\n",
    "\t\tif save:\n",
    "\t\t\tplt.savefig(f\"visualizations/{title}.jpg\")\n",
    "\t\telse:\n",
    "\t\t\tplt.show()\n",
    "\t\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def save_embedding_visualization(embedded_points, flow_artist, labels = None, device = device, title = \"Flow Embedding\", **kwargs):\n",
    "  visualize_points(embedded_points=embedded_points, flow_artist = flow_artist, labels = labels, device = device, title = title, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def collate_loss(provided_losses, prior_losses = None, loss_type = \"total\", ):\n",
    "\t\t# diffusion_loss,reconstruction_loss, smoothness_loss\n",
    "\t\tx = []\n",
    "\t\tk = \"\"\n",
    "\t\tif prior_losses is None:\n",
    "\t\t\t# if there are no prior losses, initialize a new dictionary to store these\n",
    "\t\t\tprior_losses = {}\n",
    "\t\t\tfor key in provided_losses.keys():\n",
    "\t\t\t\tprior_losses[key] = []\n",
    "\t\t\t\t# k = key\n",
    "\t\t\tprior_losses[\"total\"] = []\n",
    "\t\tfor i in range(max([len(provided_losses[\"diffusion\"]), len(provided_losses[\"smoothness\"]),len(provided_losses[\"diffusion map regularization\"]),len(provided_losses[\"flow cosine loss\"])])):\n",
    "\t\t\tx.append(i)\n",
    "\t\t\tfor key in provided_losses.keys():\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tprior_losses[key].append(provided_losses[key][i].detach().cpu().numpy())\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tprior_losses[key].append(0)\n",
    "\t\treturn prior_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Scheme\n",
    "\n",
    "This class will instantiate the Flow Embedder with preset parameters, and will train for a few hundred epochs while calling in these visualization functions, like swappable modules.\n",
    "\n",
    "The base class will take a list of visualization functions as input, and will iterate over them whenever it is called to visualize.\n",
    "\n",
    "Subsequent notebooks (05c0n) will inherit from this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "from directed_graphs.multiscale_flow_embedder import MultiscaleDiffusionFlowEmbedder\n",
    "from tqdm import trange\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class FETrainer(object):\n",
    "  def __init__(self, X, flows, labels, device = device):\n",
    "    #super(FETrainer, self).__init__()\n",
    "    self.vizfiz = [\n",
    "      save_embedding_visualization,\n",
    "    ]\n",
    "    self.FE = MultiscaleDiffusionFlowEmbedder(\n",
    "      X = X,\n",
    "      flows = flows,\n",
    "      ts = (1, 2, 4, 8),\n",
    "      sigma_graph = 0.5,\n",
    "      flow_strength_graph = 5,\n",
    "      device = device,\n",
    "      use_embedding_grid = False,\n",
    "    ).to(device)\n",
    "    self.losses = None\n",
    "    self.labels = labels\n",
    "    self.title = \"Vanilla MFE\"\n",
    "    self.epochs_between_visualization = 100\n",
    "    self.total_epochs = 10000\n",
    "    self.timestamp = datetime.datetime.now().isoformat()\n",
    "    os.mkdir(f'visualizations/{self.timestamp}')\n",
    "  \n",
    "  def fit(self):\n",
    "    num_training_runs = self.total_epochs // self.epochs_between_visualization\n",
    "    for epoch_num in trange(num_training_runs):\n",
    "      start = time.time()\n",
    "      emb_X, flow_artist, losses = self.FE.fit(n_steps = self.epochs_between_visualization)\n",
    "      stop = time.time()\n",
    "      title = f\"{self.timestamp}/{self.title} Epoch {epoch_num:03d}\"\n",
    "      self.visualize(emb_X, flow_artist, losses, title)\n",
    "      self.losses = collate_loss(provided_losses=losses, prior_losses=self.losses)\n",
    "    self.embedded_points = emb_X\n",
    "    self.flow_artist = flow_artist\n",
    "    self.losses = losses\n",
    "\n",
    "  def visualize(self, embedded_points, flow_artist, losses, title):\n",
    "    for viz_f in self.vizfiz:\n",
    "      viz_f(embedded_points= embedded_points, flow_artist = flow_artist, losses = losses, title = title, labels = self.labels)\n",
    "  \n",
    "  def training_gif(self):\n",
    "    frames = [Image.open(image) for image in glob.glob(f\"visualizations/{self.timestamp}/*.jpg\")]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(f\"{self.title}.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=10, loop=0)\n",
    "    # display in jupyter notebook\n",
    "    b64 = base64.b64encode(open(f\"{self.title}.gif\",'rb').read()).decode('ascii')\n",
    "    display(widgets.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))\n",
    "\n",
    "  def visualize_embedding(self):\n",
    "    visualize_points(embedded_points=self.embedded_points, flow_artist = self.flow_artist, labels = self.labels, title = self.title)\n",
    "\n",
    "  def visualize_loss(self, loss_type=\"all\"):\n",
    "    if loss_type == \"all\":\n",
    "      for key in self.losses.keys():\n",
    "        plt.plot(self.losses[key])\n",
    "      plt.legend(self.losses.keys(), loc='upper right')\n",
    "      plt.title(\"loss\")\n",
    "    else:\n",
    "      plt.plot(self.losses[loss_type])\n",
    "      plt.title(loss_type)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "We'll try this with our old standby test case: the swiss roll. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graphs.datasets import directed_swiss_roll_uniform, plot_directed_3d\n",
    "X, flow, labels = directed_swiss_roll_uniform(num_nodes=1000, num_spirals=2.5, radius=1, height=10, xtilt=0, ytilt=0)\n",
    "plot_directed_3d(X, flow, labels, mask_prob=0.1)\n",
    "X = torch.tensor(X)\n",
    "flow = torch.tensor(flow)\n",
    "X = X.float().to(device)\n",
    "flow = flow.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FET = FETrainer(X, flow, labels = labels, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FET.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cade4c8211a47f1835efcd6b18fca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhsAEgAYcAAP///////f//+///+v//+P//9v//9P//8///7///6v//4///2v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FET.training_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([3,3,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2076, -0.9766],\n",
       "        [ 0.2073, -0.9597],\n",
       "        [ 0.2468, -0.9546],\n",
       "        ...,\n",
       "        [-0.1753, -1.1709],\n",
       "        [-0.1755, -1.1708],\n",
       "        [-0.1757, -1.1708]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FET.FE.embedded_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0160, -1.0737],\n",
       "        [ 0.0159, -1.0652],\n",
       "        [ 0.0358, -1.0628],\n",
       "        ...,\n",
       "        [ 0.0358, -1.0628],\n",
       "        [ 0.0159, -1.0652],\n",
       "        [ 0.0160, -1.0737]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FET.FE.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.01)\n",
       "  (4): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FET.FE.FlowArtist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72d62146c604b10a47e7aceb0215bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhsAEgAYcAAP///////f//+///+v//+P//9v//9P//8///7///6v//4///2v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = [Image.open(image) for image in glob.glob(f\"visualizations/{FET.timestamp}/*.jpg\")]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(f\"{FET.title}.gif\", format=\"GIF\", append_images=frames,\n",
    "           save_all=True, duration=200, loop=0)\n",
    "# display in jupyter notebook\n",
    "b64 = base64.b64encode(open(f\"{FET.title}.gif\",'rb').read()).decode('ascii')\n",
    "display(widgets.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there 003\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hi there {3:03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb371136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import directed_graphs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff99df",
   "metadata": {},
   "source": [
    "# New Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a0f91",
   "metadata": {},
   "source": [
    "In this notebook, I will code up a DFE with new loss function discussed on July 18th, 2022.\n",
    "\n",
    "The loss function is as follows:\n",
    "\n",
    "$$\\sum\\limits_{i,j \\in V}|d_{diff}(x_i,x_j)-||\\phi(x_i)-\\phi(x_j)||_2|$$ $$+ \\beta \\sum\\limits_{i \\in V} \\sum\\limits_{k \\in N_f(i)} ||(\\phi(x_k)-\\phi(x_i))-f(\\phi(x_i))||_2$$ $$+ \\gamma \\cdot smoothness$$ $$+ \\delta \\cdot CLL (contrastive learning loss)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5796bb0",
   "metadata": {},
   "source": [
    "# Affinity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09bcf0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_from_flow(flow, directions_array, flow_strength = 1, sigma=1):\n",
    "  \"\"\"Compute probabilities of transition in the given directions based on the flow. \n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  flow : torch tensor of shape n_points x n_dims\n",
    "      _description_\n",
    "  directions_array : torch tensor of shape n_directions x n_points x n_dims. Assumed to be normalized.\n",
    "      _description_\n",
    "  sigma : int, optional\n",
    "      kernel bandwidth, by default 1\n",
    "  returns (n_points)\n",
    "  \"\"\"\n",
    "  assert len(flow.shape) == 2 # flow should only have one dimension\n",
    "  assert len(directions_array.shape) > 1 and len(directions_array.shape) < 4\n",
    "  n_directions = directions_array.shape[0]\n",
    "  # Normalize directions\n",
    "  length_of_directions = torch.linalg.norm(directions_array,dim=-1)\n",
    "  normed_directions = F.normalize(directions_array,dim=-1)\n",
    "  # and normalize flow # TODO: Perhaps reconsider\n",
    "  # Calculate flow lengths, used to scale directions to flow\n",
    "  # flow_lengths = torch.linalg.norm(flow,dim=-1)\n",
    "  if len(directions_array) == 1: # convert to 2d array if necessary\n",
    "    directions_array = directions_array[:,None] \n",
    "  # scale directions to have same norm as flow\n",
    "  # scaled_directions = normed_directions * flow_lengths[:,None].repeat(directions_array.shape[0],1,directions_array.shape[2])\n",
    "  # compute dot products as matrix multiplication\n",
    "  dot_products = (normed_directions * flow).sum(-1)\n",
    "  # take distance between flow projected onto direction and the direction\n",
    "  distance_from_flow = (torch.linalg.norm(flow,dim=1)).repeat(n_directions,1) - dot_products\n",
    "  # take absolute value\n",
    "  distance_from_flow = torch.abs(distance_from_flow)\n",
    "  # print('shape of dff',distance_from_flow.shape)\n",
    "  # add to this the length of each direction\n",
    "  distance_from_flow = flow_strength*distance_from_flow + length_of_directions\n",
    "  # put the points on rows, directions in columns\n",
    "  distance_from_flow = distance_from_flow.T\n",
    "  # take kernel of distances\n",
    "  kernel =  torch.exp(-distance_from_flow/sigma)\n",
    "  return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d532cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix_from_pointset_to_pointset(pointset1, pointset2, flow,n_neighbors=None,sigma=0.5, flow_strength=1):\n",
    "  \"\"\"Compute affinity matrix between the points of pointset1 and pointset2, using the provided flow.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  pointset1 : torch tensor, n1 x d\n",
    "      The first pointset, to calculate affinities *from*\n",
    "  pointset2 : torch tensor, n2 x d\n",
    "      The second pointset, to calculate affinities *to* (from pointset1)\n",
    "  flow : a function that, when called at a point, gives the flow at that point\n",
    "  n_neighbors : number of neighbors to include in affinity computations. All neighbors beyond it are given affinity zero\n",
    "  (currently not implemented)\n",
    "\n",
    "  Returns:\n",
    "  Affinity matrix: torch tensor of shape n1 x n2\n",
    "  \"\"\"\n",
    "  # Calculate the directions from point i in pointset 1 to point j in pointset 2\n",
    "  n1 = pointset1.shape[0]\n",
    "  n2 = pointset2.shape[0]\n",
    "  P2 = pointset2[:,:,None].repeat(1,1,n1)\n",
    "  P1 = pointset1.T.repeat(n2,1,1)\n",
    "  P3 = (P2 - P1)\n",
    "  P3 = P3.transpose(1,2)\n",
    "  # dimension 1 represents directions to point i\n",
    "  # dimension 2 represents direction from point j\n",
    "  # dimension 3 represents direction in each dimension (R^n)\n",
    "  # compute affinities from flow and directions\n",
    "  affinities = affinity_from_flow(flow,P3,sigma=sigma,flow_strength=flow_strength)\n",
    "  return affinities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c9ef2",
   "metadata": {},
   "source": [
    "# Flexible FlowArtist and Encoder (ReLU MLPs) Object Creator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8df2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def FlowArtist(dim = 2, shape = [2,4,8,4,2], device = torch.device('cpu')):\n",
    "    # Function to create tailored flow artist\n",
    "    \n",
    "    FA = nn.Sequential()\n",
    "    \n",
    "    d_len = len(shape)*2\n",
    "    d = OrderedDict()\n",
    "    d[str(0)] = nn.Linear(shape[0], shape[1])\n",
    "    for i in range(1,d_len-3):\n",
    "        if i%2 == 1:\n",
    "            d[str(i)] = nn.LeakyReLU()\n",
    "        else:\n",
    "            d[str(i)] = nn.Linear(shape[int(i/2)], shape[int(i/2)+1])\n",
    "    \n",
    "    # create MLP\n",
    "    FA = nn.Sequential(d) # d is an OrderedDictionary\n",
    "        \n",
    "    return FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bf7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardReLU(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(FeedForwardReLU, self).__init__()\n",
    "        d_len = len(shape) * 2\n",
    "        d = OrderedDict()\n",
    "        d[str(0)] = nn.Linear(shape[0], shape[1])\n",
    "        for i in range(1, d_len - 3):\n",
    "            if i % 2 == 1:\n",
    "                d[str(i)] = nn.LeakyReLU()\n",
    "            else:\n",
    "                d[str(i)] = nn.Linear(shape[int(i / 2)], shape[int(i / 2) + 1])\n",
    "        # create MLP\n",
    "        self.FA = nn.Sequential(d)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.FA(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ae48b",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818296a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_map_loss(P_graph, embedded_points):\n",
    "  num_nodes = P_graph.shape[0]\n",
    "  D_graph = torch.cdist(P_graph, P_graph)\n",
    "  D_embedding = torch.cdist(embedded_points, embedded_points)\n",
    "  loss = torch.norm(D_graph - D_embedding)**2 / (num_nodes**2)\n",
    "  return loss\n",
    "\n",
    "def near_neighbors_tensor(points, affinity_matrix, k):\n",
    "    # returns n x k (neighbors) x dimensions Tensor\n",
    "    A = affinity_matrix\n",
    "    n = A.shape[0]\n",
    "    d = points.size()[1]\n",
    "    _, indices = torch.topk(A, k)\n",
    "    \n",
    "    ret = torch.empty(size=(n,k,d)).to(device)\n",
    "    \n",
    "    for i in range(indices.size()[0]):\n",
    "        for j in range(indices.size()[1]):\n",
    "            index = indices[i][j]\n",
    "            ret[i][j] = points[index]\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def flow_neighbor_loss(points, near_neighbors, encoder, flow_artist):\n",
    "    \n",
    "    k = near_neighbors.shape[1]\n",
    "    embedded_points = encoder(points)\n",
    "    embedded_points = embedded_points[:,None,:].repeat(1,k,1)\n",
    "    \n",
    "    big_mat = encoder(near_neighbors) - embedded_points - flow_artist(embedded_points)\n",
    "    norms = torch.linalg.norm(big_mat, dim = 2)\n",
    "    \n",
    "    return torch.sum(norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f348256",
   "metadata": {},
   "source": [
    "### Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe73559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[0,0],\n",
    "         [1,0],\n",
    "         [0,1],\n",
    "         [-1,0],\n",
    "         [0,-1]]\n",
    "\n",
    "flow = [[1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [1,0],\n",
    "         [1,0]]\n",
    "\n",
    "points = torch.tensor(points).float()\n",
    "flow = torch.tensor(flow).float()\n",
    "\n",
    "#plt.scatter(points[:,0], points[:,1])\n",
    "#plt.quiver(points[:,0], points[:,1], flow[:,0], flow[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd18ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1353, 0.1353, 0.0183, 0.0025, 0.0183],\n",
       "        [0.0025, 0.1353, 0.0019, 0.0003, 0.0019],\n",
       "        [0.0183, 0.0329, 0.1353, 0.0019, 0.0025],\n",
       "        [0.1353, 0.0183, 0.0329, 0.1353, 0.0329],\n",
       "        [0.0183, 0.0329, 0.0025, 0.0019, 0.1353]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = affinity_matrix_from_pointset_to_pointset(points, points, flow)\n",
    "A\n",
    "#plt.imshow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb26616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_neighbors_tensor(points, A, 2).size()[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dfaf0",
   "metadata": {},
   "source": [
    "# Embedder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ff1e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowEmbedder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X,\n",
    "        flow,\n",
    "        sigma_graph=0.5,\n",
    "        flow_strength_graph=5,\n",
    "        embedding_dimension=2,\n",
    "        learning_rate=1e-3,\n",
    "        FAShape=(2, 4, 8, 4, 2),\n",
    "        EncShape=(3, 4, 8, 4, 2),\n",
    "        decoder=None,\n",
    "        labels=None,\n",
    "        loss_weights=None,\n",
    "        knn = 10,\n",
    "        device=torch.device(\"cpu\"),\n",
    "    ):\n",
    "        # initialize parameters\n",
    "        super(FlowEmbedder, self).__init__()\n",
    "\n",
    "        # generate default parameters\n",
    "        embedder = (\n",
    "            FeedForwardReLU(shape=EncShape)\n",
    "        )\n",
    "        loss_weights = (\n",
    "            {\n",
    "                \"points\": 1,\n",
    "                \"flow\": 1,\n",
    "                \"smoothness\": 0,\n",
    "                \"CLL\": 0,\n",
    "            }\n",
    "            if loss_weights is None\n",
    "            else loss_weights\n",
    "        )\n",
    "        self.X = X\n",
    "        self.flow = flow\n",
    "        self.sigma_graph = sigma_graph\n",
    "        self.nnodes = X.shape[0]\n",
    "        self.data_dimension = X.shape[1]\n",
    "\n",
    "        self.loss_weights = loss_weights\n",
    "        self.labels = labels\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        # set device (used for shuffling points around during visualization)\n",
    "        self.device = device\n",
    "\n",
    "        # Affinity Matrix in Ambient Space\n",
    "        self.P_graph = affinity_matrix_from_pointset_to_pointset(\n",
    "            X, X, flow, sigma=sigma_graph, flow_strength=flow_strength_graph\n",
    "        )\n",
    "        self.P_graph = F.normalize(self.P_graph, p=1, dim=1)\n",
    "        \n",
    "        # Ambient space points neighbors\n",
    "        self.knn = knn\n",
    "        self.near_neighbors = near_neighbors_tensor(self.X, self.P_graph, self.knn)\n",
    "        \n",
    "        # Flow field\n",
    "        self.FlowArtist = FlowArtist(dim = 2, \n",
    "                                     shape = FAShape, \n",
    "                                     device = torch.device('cpu')\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Autoencoder to embed the points into a low dimension\n",
    "        \n",
    "        self.embedder = embedder\n",
    "        if decoder is not None:\n",
    "            self.decoder = decoder.to(self.device)\n",
    "        else:\n",
    "            self.decoder = None\n",
    "\n",
    "        # training ops\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        # split input data into batches\n",
    "\n",
    "    def loss(self, epoch):\n",
    "        # embed points\n",
    "        self.embedded_points = self.embedder(self.X)\n",
    "        # compute diffusion loss on embedded points\n",
    "        \n",
    "        #\"\"\"\n",
    "        # compute point embedding loss according to diffusion maps\n",
    "        diffmap_loss = diffusion_map_loss(self.P_graph, self.embedded_points)\n",
    "        self.losses[\"points\"].append(diffmap_loss)\n",
    "        #\"\"\"\n",
    "        \n",
    "        #\"\"\"\n",
    "        # compute flow field loss\n",
    "        flow_loss = flow_neighbor_loss(self.X, self.near_neighbors, self.embedder, self.FlowArtist)#*10e-6\n",
    "        self.losses[\"flow\"].append(flow_loss)\n",
    "        #\"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        if epoch < 2000:\n",
    "            loss = diffmap_loss\n",
    "        else:\n",
    "             loss = diffmap_loss + flow_loss*10e-5\n",
    "        \"\"\"\n",
    "        loss = diffmap_loss + flow_loss*10e-5\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def visualize_points(self, labels=None):\n",
    "        embedded_points = self.embedder(X)\n",
    "        \n",
    "        xmin = float(torch.min(embedded_points[:,0]))\n",
    "        xmax = float(torch.max(embedded_points[:,0]))\n",
    "        ymin = float(torch.min(embedded_points[:,1]))\n",
    "        ymax = float(torch.max(embedded_points[:,1]))\n",
    "        \n",
    "        x_grid = torch.arange(xmin, xmax, (xmax-xmin)/20)\n",
    "        y_grid = torch.arange(ymin, ymax, (ymax-ymin)/20)\n",
    "        \n",
    "        grid = []\n",
    "        \n",
    "        for i in range(20):\n",
    "            for j in range(20):\n",
    "                grid.append([x_grid[i], y_grid[j]])\n",
    "        \n",
    "        grid = torch.tensor(grid).float().to(device)\n",
    "        flow = self.FlowArtist(grid)\n",
    "        \n",
    "        plt.scatter(embedded_points[:,0].cpu().detach(), embedded_points[:,1].cpu().detach(), c=labels)\n",
    "        plt.quiver(grid[:,0].cpu().detach(),grid[:,1].cpu().detach(),flow[:,0].cpu().detach(),flow[:,1].cpu().detach())\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_loss(self, loss_type=\"total\"):\n",
    "        # diffusion_loss,reconstruction_loss, smoothness_loss\n",
    "        x = []\n",
    "        k = \"\"\n",
    "        losses = {}\n",
    "        for key in self.losses.keys():\n",
    "            losses[key] = []\n",
    "            k = key\n",
    "        losses[\"total\"] = []\n",
    "        for i in range(len(self.losses[\"points\"])):\n",
    "            x.append(i)\n",
    "            for key in self.losses.keys():\n",
    "                try:\n",
    "                    losses[key].append(self.losses[key][i].detach().cpu().numpy())\n",
    "                except:\n",
    "                    losses[key].append(0)\n",
    "        if loss_type == \"all\":\n",
    "            for key in self.losses.keys():\n",
    "                plt.plot(x, losses[key])\n",
    "            plt.legend(self.losses.keys(), loc=\"upper right\")\n",
    "            plt.title(\"loss\")\n",
    "        else:\n",
    "            plt.plot(x, losses[loss_type])\n",
    "            plt.title(loss_type)\n",
    "        \n",
    "    def fit(self, n_steps=1000):\n",
    "        # train Flow Embedder on the provided graph\n",
    "        self.train()\n",
    "        # reset losses\n",
    "        self.losses = {}\n",
    "        for k in self.loss_weights.keys():\n",
    "            self.losses[k] = []\n",
    "        # self.weight_of_flow = 0\n",
    "        for step in trange(n_steps):\n",
    "            # vary weight of each part of loss function\n",
    "            \"\"\" \n",
    "            if step == 100:\n",
    "                self.weight_of_flow = 1\n",
    "            if step == 200:\n",
    "                self.weight_of_flow = 0.5\n",
    "            \"\"\"\n",
    "            self.optim.zero_grad()\n",
    "            # compute loss\n",
    "            loss = self.loss(step)\n",
    "            if loss.isnan():\n",
    "                print(\"Final loss was nan\")\n",
    "                raise NotImplementedError\n",
    "            # compute gradient and step backwards\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            # print progress report after every 500 epochs\n",
    "            #\"\"\"\n",
    "            if step % 100 == 0:\n",
    "                print(f\"EPOCH {step}.\")\n",
    "                self.visualize_points(labels)\n",
    "            #\"\"\"\n",
    "            # TODO: Criteria to automatically end training\n",
    "        # print(\"Exiting training with loss \",loss)\n",
    "        # return self.embedded_points, self.FlowArtist, self.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acc4a0",
   "metadata": {},
   "source": [
    "# Testing library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c68f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2., 1.],\n",
       "        [5., 4., 6.],\n",
       "        [9., 7., 8.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [[3,2,1],[5,4,6],[9,7,8]]\n",
    "A = torch.tensor(A).float()\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6156ccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 0],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = torch.topk(A, 2)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681516ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = np.empty(shape=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1fc299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed80ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0.],\n",
       "         [0., 1.]],\n",
       "\n",
       "        [[1., 0.],\n",
       "         [0., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [[1,0], [0,1]]\n",
    "p = torch.tensor(p).float()\n",
    "\n",
    "p.repeat(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ec46a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b923dbfdd00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmin = 0\n",
    "xmax = 20\n",
    "ymin = 0\n",
    "ymax = 20\n",
    "\n",
    "x_grid = torch.arange(xmin, xmax, (xmax-xmin)/20)\n",
    "y_grid = torch.arange(ymin, ymax, (ymax-ymin)/20)\n",
    "        \n",
    "grid = []\n",
    "        \n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        grid.append([x_grid[i], y_grid[j]])\n",
    "    \n",
    "grid = np.asarray(grid)\n",
    "    \n",
    "plt.scatter(grid[:,0], grid[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc1af5",
   "metadata": {},
   "source": [
    "# Testing the Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d27bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp multiscale_flow_embedder\n",
    "from nbdev.showdoc import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import directed_graphs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05c Multiscale Flow Embeddings with a Grid\n",
    "The problem with the Diffusion Flow Embedder (05b) is that, although it minimizes the loss quite well, achieving 0 cost only requires the network to replicate the graph's *affinity* matrix within the embedding. Consequently, the embedding only preserves near neighbors; like tSNE, it willfully distorts global structure.\n",
    "\n",
    "This manifests in, for example 05b05 and 05b05a, where we see that the spiral (and the swiss roll) are not *unrolled*, as we'd like -- but are either left coiled, as in their projections, or wrapped oddly. The affinity matrices of the embeddings are beautiful. They have no way of telling how weird the global structure is. \n",
    "\n",
    "As a result, the flows learnt by the method are unnecessarily complex, and tend to wrap around the manifold. The flows are only used for near neighbor connectivity, hence there is no incentive to learn anything that makes sense in long ranges.\n",
    "\n",
    "This notebook is motivated by a suspicion that these effects can be greatly lessened with two novel additions:\n",
    "1. *multiscale* diffusion probability comparisons  -- between $P_{graph}^t$ and $P_{embedding}^t$ for several values of $t$, but only in which\n",
    "2. a *grid* connects points in the embedding space in a way the ambient points aren't connected.\n",
    "\n",
    "Much of the machinery for this was already developed in 05b. We need only introduce the grid, and a multiscale loss.\n",
    "\n",
    "I'm additionally going to try to make the class as *modular* as possible, to avoid the syndrome of doing everything within one giant code block with a class that has dozens of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from directed_graphs.diffusion_flow_embedding import affinity_matrix_from_pointset_to_pointset, smoothness_of_vector_field\n",
    "def compute_grid(X,grid_width=20):\n",
    "  \"\"\" Returns a grid of points which bounds the points X. \n",
    "  The grid has 'grid_width' dots in both length and width.\n",
    "  Accepts X, tensor of shape n x 2\n",
    "  Returns tensor of shape grid_width^2 x 2\"\"\"\n",
    "  # TODO: This currently only supports \n",
    "  # find support of points\n",
    "  minx = (min(X[:,0])-1).detach()\n",
    "  maxx = (max(X[:,0])+1).detach()\n",
    "  miny = (min(X[:,1])-1).detach()\n",
    "  maxy = (max(X[:,1])+1).detach()\n",
    "  # form grid around points\n",
    "  x, y = torch.meshgrid(torch.linspace(minx,maxx,steps=grid_width),torch.linspace(miny,maxy,steps=grid_width))\n",
    "  xy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float()\n",
    "  xy_t = xy_t.reshape(grid_width**2,2)\n",
    "  return xy_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cornerstone of this method will be the powering of the diffusion matrix, which must intersperse jumping between points in the dataset and in the surrounding grid. Traditional matrix powering will do, provided we add the grid points to the dataset before powering, and then take them out afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from directed_graphs.diffusion_flow_embedding import affinity_matrix_from_pointset_to_pointset, GaussianVectorField\n",
    "import torch.nn.functional as F\n",
    "def diffusion_matrix_with_grid_points(X, grid, flow_function, t, sigma,flow_strength):\n",
    "  n_points = X.shape[0]\n",
    "  # combine the points and the grid\n",
    "  points_and_grid = torch.concat([X,grid],dim=0)\n",
    "  # get flows at each point\n",
    "  flow_per_point = flow_function(points_and_grid)\n",
    "  # take a diffusion matrix\n",
    "  A = affinity_matrix_from_pointset_to_pointset(points_and_grid,points_and_grid, flows = flow_per_point, sigma = sigma, flow_strength=flow_strength)\n",
    "  P = torch.diag(1/A.sum(1)) @ A # TODO: is there a more efficient way to do this?\n",
    "  # TODO: Should we remove self affinities? Probably not, as lazy random walks are advantageous when powering\n",
    "  # Power the matrix to t steps\n",
    "  Pt = torch.matrix_power(P,t)\n",
    "  # Recover the transition probabilities between the points, and renormalize them\n",
    "  P_points = P[:n_points,:n_points]\n",
    "  P_points = torch.diag(1/P_points.sum(1)) @ P_points\n",
    "  # return diffusion probs between points\n",
    "  return P_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9890e-01, 1.0940e-03, 3.8218e-06],\n",
       "        [4.6828e-01, 5.3171e-01, 7.3682e-06],\n",
       "        [1.2278e-05, 3.5147e-03, 9.9647e-01]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "B = torch.rand(5,2)\n",
    "K = GaussianVectorField(2,25,device)\n",
    "out = diffusion_matrix_with_grid_points(A,B,K,1, 0.5, 4)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from directed_graphs.diffusion_flow_embedding import GaussianVectorField, smoothness_of_vector_field\n",
    "class MultiscaleDiffusionFlowEmbedder(torch.nn.Module):\n",
    "\tdef __init__(self, \n",
    "\t\t\t\t\t\t\tX, \n",
    "\t\t\t\t\t\t\tflows, \n",
    "\t\t\t\t\t\t\tts = [1,2,4,8], \n",
    "\t\t\t\t\t\t\tsigma_graph = 0.5, \n",
    "\t\t\t\t\t\t\tsigma_embedding=0.5, \n",
    "\t\t\t\t\t\t\tflow_strength_graph=5, \n",
    "\t\t\t\t\t\t\tflow_strength_embedding=5, \n",
    "\t\t\t\t\t\t\tembedding_dimension=2, \n",
    "\t\t\t\t\t\t\tdevice=torch.device('cpu'), \n",
    "\t\t\t\t\t\t\tautoencoder_shape = [10,30,10], \n",
    "\t\t\t\t\t\t\tflow_artist = \"gaussian\",\n",
    "\t\t\t\t\t\t\tflow_artist_shape = [30,20,10], \n",
    "\t\t\t\t\t\t\tlearning_rate = 1e-5,\n",
    "\t\t\t\t\t\t\tsmoothness = 1,\n",
    "\t\t\t\t\t\t\tembedding_bounds = 4,\n",
    "\t\t\t\t\t\t\tnum_gaussians = 25,\n",
    "\t\t\t\t\t\t\tlabels = None,    \n",
    "\t\t\t\t\t\t\tloss_weights = {\n",
    "\t\t\t\t\t\t\t\t\"diffusion\":0.7,\n",
    "\t\t\t\t\t\t\t\t\"smoothness\":0.2,\n",
    "\t\t\t\t\t\t\t\t\"reconstruction\":0.1\n",
    "\t\t\t\t\t\t\t}  \n",
    "\t\t\t\t\t\t\t):\n",
    "\t\t# initialize parameters\n",
    "\t\tsuper(MultiscaleDiffusionFlowEmbedder, self).__init__()\n",
    "\t\tself.X = X\n",
    "\t\tself.ground_truth_flows = flows\n",
    "\t\tself.ts = ts\n",
    "\t\tself.sigma_embedding = sigma_embedding\n",
    "\t\tself.sigma_graph = sigma_graph\n",
    "\t\tself.nnodes = X.shape[0]\n",
    "\t\tself.data_dimension = X.shape[1]\n",
    "\t\tself.losses = {}\n",
    "\t\tself.eps = 0.001\n",
    "\t\tself.loss_weights = loss_weights\n",
    "\t\tself.embedding_bounds = embedding_bounds # will constrain embedding to live in -n, n in each dimension\n",
    "\t\tself.labels = labels\n",
    "\t\tself.flow_strength = nn.Parameter(torch.tensor(flow_strength_embedding).float())\n",
    "\t\tself.embedding_dimension = embedding_dimension\n",
    "\t\t# set device (used for shuffling points around during visualization)\n",
    "\t\tself.device = device\n",
    "\t\t# Compute P^t of the graph, the powered diffusion matrix\n",
    "\t\t# TODO: This can be optimized using landmarks, etc. For now it's straight sparse matrix multiplication\n",
    "\t\t# TODO: Migrate to a specialized function for dataset affinity calculation, with automatic kernel bandwidth selection, and the like\n",
    "\t\t\n",
    "\t\tself.P_graph = affinity_matrix_from_pointset_to_pointset(X,X,flows,sigma=sigma_graph,flow_strength=flow_strength_graph)\n",
    "\t\tself.P_graph = torch.diag(1/self.P_graph.sum(axis=1)) @ self.P_graph\n",
    "\t\t# compute matrix powers \n",
    "\t\t# TODO: Could reuse previous powers to speed this up\n",
    "\t\tself.P_graph_ts = [torch.matrix_power(self.P_graph,t) for t in self.ts]\n",
    "\n",
    "\t\t# Flow field\n",
    "\t\t# Gaussian model\n",
    "\t\tif flow_artist == \"gaussian\":\n",
    "\t\t\tself.FlowArtist = GaussianVectorField(embedding_dimension,num_gaussians, device=device).to(device)\n",
    "\t\telse:\n",
    "\t\t\tself.FlowArtist = nn.Sequential(nn.Linear(self.embedding_dimension, flow_artist_shape[0]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(flow_artist_shape[0], flow_artist_shape[1]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(flow_artist_shape[1], flow_artist_shape[2]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(flow_artist_shape[2], self.embedding_dimension)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\t\t# Autoencoder to embed the points into a low dimension\n",
    "\t\tself.encoder = nn.Sequential(nn.Linear(self.data_dimension, autoencoder_shape[0]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(autoencoder_shape[0], autoencoder_shape[1]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(autoencoder_shape[1], self.embedding_dimension))\n",
    "\t\tself.decoder = nn.Sequential(nn.Linear(self.embedding_dimension, autoencoder_shape[1]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(autoencoder_shape[1], autoencoder_shape[0]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.LeakyReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(autoencoder_shape[0], self.data_dimension))\n",
    "\t\t# training ops\n",
    "\t\tself.KLD = nn.KLDivLoss(reduction='batchmean',log_target=False)\n",
    "\t\tself.MSE = nn.MSELoss()\n",
    "\t\t# testing\n",
    "\t\t# self.KLD = nn.NLLLoss()\n",
    "\t\tself.optim = torch.optim.Adam(self.parameters(), lr = learning_rate)\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\tdef diffusion_loss(self):\n",
    "\t\t# embed points\n",
    "\t\tself.embedded_points = self.encoder(self.X)\n",
    "\t\t# compute grid around points\n",
    "\t\tself.grid = compute_grid(self.embedded_points)\n",
    "\t\t# normalize embedded points to lie within -self.embedding_bounds, self.embedding_bounds\n",
    "\t\t# if any are trying to escape, constrain them to lie on the edges\n",
    "\t\t# self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds] = self.embedding_bounds * (self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds])/torch.abs(self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds])\n",
    "\t\t# self.embedded_points[:,1][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds] = self.embedding_bounds * (self.embedded_points[:,1][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds])/torch.abs(self.embedded_points[:,0][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds])\n",
    "\t\t# compute embedding diffusion matrix, using including diffusion to grid points\n",
    "\t\tfor i,t in enumerate(self.ts):\n",
    "\t\t\tself.P_embedding_ts[i] = diffusion_matrix_with_grid_points(X = self.embedded_points, grid=self.grid, flow_function = self.FlowArtist, t = t, sigma = self.sigma_embedding, flow_strength=self.flow_strength)\n",
    "\t\t# take KL divergence between P embedding ts and P graph ts\n",
    "\t\tdiffusion_loss = 0\n",
    "\t\tfor i in range(len(self.ts)):\n",
    "\t\t\tlog_P_embedding_t = torch.log(self.P_embedding_ts[i])\n",
    "\t\t\tif log_P_embedding_t.is_sparse:\n",
    "\t\t\t\tdiffusion_loss_for_t = self.KLD(log_P_embedding_t.to_dense(),self.P_graph_ts[i].to_dense())\n",
    "\t\t\telse:\n",
    "\t\t\t\tdiffusion_loss_for_t = self.KLD(log_P_embedding_t,self.P_graph_t)\n",
    "\t\t\tdiffusion_loss += diffusion_loss_for_t\n",
    "\t\tself.losses['diffusion'].append(diffusion_loss)\n",
    "\t\treturn diffusion_loss\n",
    "\n",
    "\tdef loss(self):\n",
    "\t\tdiffusion_loss = self.diffusion_loss()\n",
    "\n",
    "\t\t# compute autoencoder loss\n",
    "\t\tX_reconstructed = self.decoder(self.embedded_points)\n",
    "\t\treconstruction_loss = self.MSE(X_reconstructed, self.X)\n",
    "\t\tself.losses['reconstruction'].append(reconstruction_loss)\n",
    "\t\n",
    "\t\t# regularizations\n",
    "\t\tsmoothness_loss = smoothness_of_vector_field(self.embedded_points,self.FlowArtist,device=self.device,grid_width=20)\n",
    "\t\tself.losses['smoothness'].append(smoothness_loss)\n",
    "\t\t\n",
    "\t\tcost = (self.loss_weights['diffusion']*diffusion_loss \n",
    "\t\t+ self.loss_weights['reconstruction']*reconstruction_loss \n",
    "\t\t+ self.loss_weights['smoothness']*smoothness_loss)\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef visualize_points(self, labels = None):\n",
    "\t\t# controls the x and y axes of the plot\n",
    "\t\t# linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)\n",
    "\t\tif labels is None:\n",
    "\t\t\tlabels = self.labels\n",
    "\t\tuv = self.FlowArtist(self.grid.detach().cpu()).detach()\n",
    "\t\tu = uv[:,0].cpu()\n",
    "\t\tv = uv[:,1].cpu()\n",
    "\t\tx = self.grid.detach().cpu()[:,0]\n",
    "\t\ty = self.grid.detach().cpu()[:,1]\n",
    "\t\t# quiver \n",
    "\t\t# \tplots a 2D field of arrows\n",
    "\t\t# \tquiver([X, Y], U, V, [C], **kw); \n",
    "\t\t# \tX, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.\n",
    "\t\tif labels is not None:\n",
    "\t\t\tsc = plt.scatter(self.embedded_points[:,0].detach().cpu(),self.embedded_points[:,1].detach().cpu(), c=labels)\n",
    "\t\t\tplt.legend()\n",
    "\t\telse:\n",
    "\t\t\tsc = plt.scatter(self.embedded_points[:,0].detach().cpu(),self.embedded_points[:,1].detach().cpu())\n",
    "\t\tplt.suptitle(\"Flow Embedding\")\n",
    "\t\tplt.quiver(x,y,u,v)\n",
    "\t\t# Display all open figures.\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\tdef visualize_diffusion_matrices(self):\n",
    "\t\tfig, axs = plt.subplots(1,2)\n",
    "\t\taxs[0].set_title(f\"Ambient $P^{self.t}$\")\n",
    "\t\taxs[0].imshow(self.P_graph_t.detach().cpu().numpy())\n",
    "\t\taxs[1].set_title(f\"Embedding $P^{self.t}$\")\n",
    "\t\taxs[1].imshow(self.P_embedding_t.detach().cpu().numpy())\n",
    "\t\tplt.show()\n",
    "\n",
    "\tdef fit(self,n_steps = 1000):\n",
    "\t\t# train Flow Embedder on the provided graph\n",
    "\t\tself.train()\n",
    "\t\t# self.weight_of_flow = 0\n",
    "\t\tfor step in trange(n_steps):\n",
    "\t\t\t# if step == 100:\n",
    "\t\t\t# \tself.weight_of_flow = 1\n",
    "\t\t\t# if step == 200:\n",
    "\t\t\t# \tself.weight_of_flow = 0.5\n",
    "\t\t\tself.optim.zero_grad()\n",
    "\t\t\t# compute loss\n",
    "\t\t\tloss = self.loss()\n",
    "\t\t\t# print(\"loss is \",loss)\n",
    "\t\t\t# compute gradient and step backwards\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optim.step()\n",
    "\t\t\tif step % 100 == 0:\n",
    "\t\t\t\tprint(f\"EPOCH {step}. Loss {loss}. Flow strength {self.flow_strength}. Weight of flow {self.weight_of_flow} Heatmap of P embedding is \")\n",
    "\t\t\t\tself.visualize_diffusion_matrices()\n",
    "\t\t\t\tself.visualize_points()\n",
    "\t\t\t# TODO: Criteria to automatically end training\n",
    "\t\tprint(\"Exiting training with loss \",loss)\n",
    "\t\treturn self.embedded_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyg_from_source')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

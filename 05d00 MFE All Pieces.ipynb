{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import directed_graphs\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_from_flow(flows, directions_array, flow_strength = 1, sigma=1):\n",
    "  \"\"\"Compute probabilities of transition in the given directions based on the flow. \n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  flows : torch tensor of shape n_points x n_dims\n",
    "      _description_\n",
    "  directions_array : torch tensor of shape n_directions x n_points x n_dims. Assumed to be normalized.\n",
    "      _description_\n",
    "  sigma : int, optional\n",
    "      kernel bandwidth, by default 1\n",
    "  returns (n_points)\n",
    "  \"\"\"\n",
    "  assert len(flows.shape) == 2 # flows should only have one dimension\n",
    "  assert len(directions_array.shape) > 1 and len(directions_array.shape) < 4\n",
    "  n_directions = directions_array.shape[0]\n",
    "  # Normalize directions\n",
    "  length_of_directions = torch.linalg.norm(directions_array,dim=-1)\n",
    "  normed_directions = F.normalize(directions_array,dim=-1)\n",
    "  # and normalize flows # TODO: Perhaps reconsider\n",
    "  # Calculate flow lengths, used to scale directions to flow\n",
    "  # flow_lengths = torch.linalg.norm(flows,dim=-1)\n",
    "  if len(directions_array) == 1: # convert to 2d array if necessary\n",
    "    directions_array = directions_array[:,None] \n",
    "  # scale directions to have same norm as flow\n",
    "  # scaled_directions = normed_directions * flow_lengths[:,None].repeat(directions_array.shape[0],1,directions_array.shape[2])\n",
    "  # compute dot products as matrix multiplication\n",
    "  dot_products = (normed_directions * flows).sum(-1)\n",
    "  # take distance between flow projected onto direction and the direction\n",
    "  distance_from_flow = (torch.linalg.norm(flows,dim=1)).repeat(n_directions,1) - dot_products\n",
    "  # take absolute value\n",
    "  distance_from_flow = torch.abs(distance_from_flow)\n",
    "  # print('shape of dff',distance_from_flow.shape)\n",
    "  # add to this the length of each direction\n",
    "  distance_from_flow = flow_strength*distance_from_flow + length_of_directions\n",
    "  # put the points on rows, directions in columns\n",
    "  distance_from_flow = distance_from_flow.T\n",
    "  # take kernel of distances\n",
    "  kernel =  torch.exp(-distance_from_flow/sigma)\n",
    "  return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f07d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix_from_pointset_to_pointset(pointset1, pointset2, flows,n_neighbors=None,sigma=0.5, flow_strength=1):\n",
    "  \"\"\"Compute affinity matrix between the points of pointset1 and pointset2, using the provided flow.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  pointset1 : torch tensor, n1 x d\n",
    "      The first pointset, to calculate affinities *from*\n",
    "  pointset2 : torch tensor, n2 x d\n",
    "      The second pointset, to calculate affinities *to* (from pointset1)\n",
    "  flow : a function that, when called at a point, gives the flow at that point\n",
    "  n_neighbors : number of neighbors to include in affinity computations. All neighbors beyond it are given affinity zero\n",
    "  (currently not implemented)\n",
    "\n",
    "  Returns:\n",
    "  Affinity matrix: torch tensor of shape n1 x n2\n",
    "  \"\"\"\n",
    "  # Calculate the directions from point i in pointset 1 to point j in pointset 2\n",
    "  n1 = pointset1.shape[0]\n",
    "  n2 = pointset2.shape[0]\n",
    "  P2 = pointset2[:,:,None].repeat(1,1,n1)\n",
    "  P1 = pointset1.T.repeat(n2,1,1)\n",
    "  P3 = (P2 - P1)\n",
    "  P3 = P3.transpose(1,2)\n",
    "  # dimension 1 represents directions to point i\n",
    "  # dimension 2 represents direction from point j\n",
    "  # dimension 3 represents direction in each dimension (R^n)\n",
    "  # compute affinities from flows and directions\n",
    "  affinities = affinity_from_flow(flows,P3,sigma=sigma,flow_strength=flow_strength)\n",
    "  return affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianVectorField(nn.Module):\n",
    "  def __init__(self,n_dims, n_gaussians, device, random_initalization = True):\n",
    "    super(GaussianVectorField, self).__init__()\n",
    "    self.n_dims = n_dims\n",
    "    # each gaussian has a mean and a variance, which are initialized randomly, but\n",
    "    # are afterwards tuned by the network\n",
    "    self.means = torch.nn.Parameter(torch.rand(n_gaussians,n_dims)*8 - 4).to(device)\n",
    "    if random_initalization:\n",
    "      vecs = torch.randn(n_gaussians,n_dims)\n",
    "    else:\n",
    "      vecs = torch.ones(n_gaussians,n_dims)\n",
    "    vecs = vecs / torch.linalg.norm(vecs, dim=1)[:,None]\n",
    "    self.vectors = torch.nn.Parameter(vecs).to(device)\n",
    "  def forward(self,points):\n",
    "    # evaluates the vector field at each point\n",
    "    # First, take distances between the points and the means\n",
    "    dist_between_pts_and_means = torch.cdist(points,self.means)\n",
    "    # print(\"distances between points and means\",dist_between_pts_and_means)\n",
    "    # apply kernel to this\n",
    "    # creates n_points x n_means array\n",
    "    kernel_from_mean = torch.exp(-(dist_between_pts_and_means**2))\n",
    "    # print(\"kernalized\",kernel_from_mean)\n",
    "    # multiply kernel value by vectors associated with each Gaussian\n",
    "    kernel_repeated = kernel_from_mean[:,:,None].repeat(1,1,self.n_dims)\n",
    "    # print('kernel repeated has shape',kernel_repeated.shape, 'and vecs has shape', self.vectors.shape)\n",
    "    kernel_times_vectors = kernel_repeated * self.vectors\n",
    "    # creates tensor of shape\n",
    "    # n_points x n_means x n_dims\n",
    "    # collapse along dim 1 to sum vectors along dimension\n",
    "    vector_field = kernel_times_vectors.sum(dim=1)\n",
    "    return vector_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_kernel(D, sigma=0.7, alpha = 1):\n",
    "  \"\"\"Computes anisotropic kernel of given distances matrix.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  D : ndarray or sparse\n",
    "  sigma : float, optional\n",
    "      Kernel bandwidth, by default 0.7\n",
    "  alpha : int, optional\n",
    "      Degree of density normalization, from 0 to 1; by default 1\n",
    "  This is a good function.\n",
    "  \"\"\"\n",
    "  W = torch.exp(-D**2/(2*sigma**2))\n",
    "  # Additional normalization step for density\n",
    "  D = torch.diag(1/(torch.sum(W,axis=1)**alpha)) \n",
    "  W = D @ W @ D\n",
    "  return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ad3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def FlowArtist(FA_type,dim = 2, num_gauss = 0, shape = [2,4,8,4,2], device = torch.device('cpu')):\n",
    "    # Function to create tailored flow artist\n",
    "    \n",
    "    FA = nn.Sequential()\n",
    "    \n",
    "    if FA_type == \"gaussian\": # default = Gaussian model\n",
    "        FA = GaussianVectorField(dim,num_gauss, device=device)\n",
    "    elif FA_type == \"ReLU\": # ReLu\n",
    "        d_len = len(shape)*2\n",
    "        d = OrderedDict()\n",
    "        d[str(0)] = nn.Linear(shape[0], shape[1])\n",
    "        for i in range(1,d_len-3):\n",
    "            if i%2 == 1:\n",
    "                d[str(i)] = nn.LeakyReLU()\n",
    "            else:\n",
    "                d[str(i)] = nn.Linear(shape[int(i/2)], shape[int(i/2)+1])\n",
    "        # create MLP\n",
    "        FA = nn.Sequential(d)\n",
    "        \n",
    "    elif FA_type == \"tanh\": # ReLu dim,2,4,8,4,2,dim\n",
    "        shape = [2,4,8,4,2]\n",
    "        FA = nn.Sequential(nn.Linear(dim, shape[0]),\n",
    "                           nn.tanh(),\n",
    "                           nn.Linear(shape[0], shape[1]),\n",
    "                           nn.tanh(),\n",
    "                           nn.Linear(shape[1], shape[2]),\n",
    "                           nn.tanh(),\n",
    "                           nn.Linear(shape[2], shape[3]),\n",
    "                           nn.tanh(),\n",
    "                           nn.Linear(shape[3], shape[4]),\n",
    "                           nn.tanh(),\n",
    "                           nn.Linear(shape[4], dim))\n",
    "        \n",
    "    return FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothness_of_vector_field(embedded_points, vector_field_function, device, use_grid = True, grid_width = 20):\n",
    "  if use_grid:\n",
    "    # find support of points\n",
    "    minx = (min(embedded_points[:,0])-1).detach()\n",
    "    maxx = (max(embedded_points[:,0])+1).detach()\n",
    "    miny = (min(embedded_points[:,1])-1).detach()\n",
    "    maxy = (max(embedded_points[:,1])+1).detach()\n",
    "    # form grid around points\n",
    "    x, y = torch.meshgrid(torch.linspace(minx,maxx,steps=grid_width),torch.linspace(miny,maxy,steps=grid_width))\n",
    "    xy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float()\n",
    "    xy_t = xy_t.reshape(grid_width**2,2).to(device)\n",
    "    points_to_test = xy_t\n",
    "  else:\n",
    "    points_to_test = embedded_points\n",
    "  # Compute distances between points\n",
    "  # TODO: Can compute A analytically for grid graph, don't need to run kernel\n",
    "  Dists = torch.cdist(points_to_test,points_to_test)\n",
    "  A = anisotropic_kernel(Dists)\n",
    "  # Get degree matrix and build graph laplacian\n",
    "  D = A.sum(axis=1)\n",
    "  L = torch.diag(D) - A\n",
    "  # comment this out in production\n",
    "  # plt.imshow(L)\n",
    "  # print(L)\n",
    "  # compute vector field at each grid point\n",
    "  vecs = vector_field_function(points_to_test)\n",
    "  x_vecs = vecs[:,0]\n",
    "  y_vecs = vecs[:,1]\n",
    "  # compute smoothness of each x and y and add them # TODO: There are other ways this could be done\n",
    "  x_smoothness = (x_vecs.T @ L @ x_vecs) / torch.max(torch.linalg.norm(x_vecs)**2, torch.tensor(1e-5))\n",
    "  y_smoothness = (y_vecs.T @ L @ y_vecs) / torch.max(torch.linalg.norm(y_vecs)**2, torch.tensor(1e-5))\n",
    "  total_smoothness = x_smoothness + y_smoothness\n",
    "  return total_smoothness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ddce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grid(X,grid_width=20):\n",
    "  \"\"\" Returns a grid of points which bounds the points X. \n",
    "  The grid has 'grid_width' dots in both length and width.\n",
    "  Accepts X, tensor of shape n x 2\n",
    "  Returns tensor of shape grid_width^2 x 2\"\"\"\n",
    "  # TODO: This currently only supports \n",
    "  # find support of points\n",
    "  minx = float(torch.min(X[:,0])-0.1) # TODO: use torch.min, try without detach\n",
    "  maxx = float(torch.max(X[:,0])+0.1)\n",
    "  miny = float(torch.min(X[:,1])-0.1)\n",
    "  maxy = float(torch.max(X[:,1])+0.1)\n",
    "  # form grid around points\n",
    "  x, y = torch.meshgrid(torch.linspace(minx,maxx,steps=grid_width),torch.linspace(miny,maxy,steps=grid_width))\n",
    "  xy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float()\n",
    "  xy_t = xy_t.reshape(grid_width**2,2).detach()\n",
    "  return xy_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d738da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_matrix_with_grid_points(X, grid, flow_function, t, sigma,flow_strength):\n",
    "  n_points = X.shape[0]\n",
    "  # combine the points and the grid\n",
    "  points_and_grid = torch.concat([X,grid],dim=0)\n",
    "  # get flows at each point\n",
    "  flow_per_point = flow_function(points_and_grid)\n",
    "  # take a diffusion matrix\n",
    "  A = affinity_matrix_from_pointset_to_pointset(points_and_grid,points_and_grid, flows = flow_per_point, sigma = sigma, flow_strength=flow_strength)\n",
    "  P = F.normalize(A, p=1, dim=-1)\n",
    "  # TODO: Should we remove self affinities? Probably not, as lazy random walks are advantageous when powering\n",
    "  # Power the matrix to t steps\n",
    "  Pt = torch.matrix_power(P,t)\n",
    "  # Recover the transition probabilities between the points, and renormalize them\n",
    "  Pt_points = Pt[:n_points,:n_points]\n",
    "  # Pt_points = torch.diag(1/Pt_points.sum(1)) @ Pt_points\n",
    "  Pt_points = F.normalize(Pt_points, p=1, dim=1)\n",
    "  # return diffusion probs between points\n",
    "  return Pt_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c21093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardReLU(nn.Module):\n",
    "  def __init__(self, shape):\n",
    "    super(FeedForwardReLU, self).__init__()\n",
    "    d_len = len(shape)*2\n",
    "    d = OrderedDict()\n",
    "    d[str(0)] = nn.Linear(shape[0], shape[1])\n",
    "    for i in range(1,d_len-3):\n",
    "        if i%2 == 1:\n",
    "            d[str(i)] = nn.LeakyReLU()\n",
    "        else:\n",
    "            d[str(i)] = nn.Linear(shape[int(i/2)], shape[int(i/2)+1])\n",
    "    # create MLP\n",
    "    self.FA = nn.Sequential(d)\n",
    "  def forward(self, X):\n",
    "    return self.FA(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiscaleDiffusionFlowEmbedder(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 X, \n",
    "                 flows, \n",
    "                 ts = (1,2,4,8), \n",
    "                 sigma_graph = 0.5,\n",
    "                 sigma_embedding=0.5,\n",
    "                 flow_strength_graph=5, \n",
    "                 flow_strength_embedding=5,\n",
    "                 embedding_dimension=2,\n",
    "                 learning_rate = 1e-3,\n",
    "                 flow_artist = \"ReLU\",\n",
    "                 flow_artist_shape = (2,4,8,4,2),\n",
    "                 num_flow_gaussians = 25,\n",
    "                 embedder = None,\n",
    "                 decoder = None,\n",
    "                 labels = None,\n",
    "                 loss_weights = None,\n",
    "                 device=torch.device('cpu'),\n",
    "                ):\n",
    "        # generate default parameters\n",
    "        embedder = FeedForwardReLU(shape=(3,4,8,4,2)) if embedder is None else embedder\n",
    "        decoder = FeedForwardReLU(shape=(2,4,8,4,3)) if decoder is None else decoder\n",
    "        loss_weights = {\n",
    "            \"diffusion\":1,\n",
    "            \"smoothness\":0,\n",
    "            \"reconstruction\":0,\n",
    "            \"diffusion map regularization\":0,\n",
    "            \"flow cosine loss\": 0,\n",
    "        } if loss_weights is None else loss_weights\n",
    "\n",
    "        # initialize parameters\n",
    "        super(MultiscaleDiffusionFlowEmbedder, self).__init__()\n",
    "        self.X = X\n",
    "        self.ground_truth_flows = flows\n",
    "        self.ts = ts\n",
    "        self.sigma_embedding = sigma_embedding\n",
    "        self.sigma_graph = sigma_graph\n",
    "        self.nnodes = X.shape[0]\n",
    "        self.data_dimension = X.shape[1]\n",
    "        \n",
    "        self.eps = 0.001\n",
    "        self.loss_weights = loss_weights\n",
    "        self.labels = labels\n",
    "        self.flow_strength = torch.tensor(flow_strength_embedding).float()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        # set device (used for shuffling points around during visualization)\n",
    "        self.device = device\n",
    "        # Used for \n",
    "        self.losses = {}\n",
    "        for k in self.loss_weights.keys():\n",
    "            self.losses[k] = []\n",
    "        \n",
    "        self.P_graph = affinity_matrix_from_pointset_to_pointset(X,X,flows,sigma=sigma_graph,flow_strength=flow_strength_graph)\n",
    "        self.P_graph = F.normalize(self.P_graph, p=1, dim=1)\n",
    "        # torch.diag(1/self.P_graph.sum(axis=1)) @ self.P_graph\n",
    "        # compute matrix powers \n",
    "        # TODO: Could reuse previous powers to speed this up\n",
    "        self.P_graph_ts = [torch.matrix_power(self.P_graph,t) for t in self.ts]\n",
    "        self.P_embedding_ts = [None for i in self.ts]\n",
    "        # Flow field\n",
    "        self.FlowArtist = FlowArtist(flow_artist, dim=self.embedding_dimension, num_gauss = num_flow_gaussians, shape = flow_artist_shape, device = self.device).to(self.device)\n",
    "\n",
    "        # Autoencoder to embed the points into a low dimension\n",
    "        self.embedder = embedder.to(self.device)\n",
    "        if decoder is not None:\n",
    "            self.decoder = decoder.to(self.device)\n",
    "        else:\n",
    "            self.decoder = None\n",
    "\n",
    "        # training ops\n",
    "        self.KLD = nn.KLDivLoss(reduction='batchmean',log_target=False)\n",
    "        self.MSE = nn.MSELoss()\n",
    "        # self.KLD = homemade_KLD # when running on mac\n",
    "        self.epsilon = 1e-6 # set zeros to eps\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr = learning_rate)\n",
    "\n",
    "    def diffusion_loss(self):\n",
    "        # compute grid around points\n",
    "        self.grid = compute_grid(self.embedded_points).to(self.device)\n",
    "        # normalize embedded points to lie within -self.embedding_bounds, self.embedding_bounds\n",
    "        # if any are trying to escape, constrain them to lie on the edges\n",
    "        # self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds] = self.embedding_bounds * (self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds])/torch.abs(self.embedded_points[:,0][torch.abs(self.embedded_points[:,0]) > self.embedding_bounds])\n",
    "        # self.embedded_points[:,1][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds] = self.embedding_bounds * (self.embedded_points[:,1][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds])/torch.abs(self.embedded_points[:,0][torch.abs(self.embedded_points[:,1]) > self.embedding_bounds])\n",
    "        # compute embedding diffusion matrix, using including diffusion to grid points\n",
    "        for i,t in enumerate(self.ts):\n",
    "            self.P_embedding_ts[i] = diffusion_matrix_with_grid_points(X = self.embedded_points, grid=self.grid, flow_function = self.FlowArtist, t = t, sigma = self.sigma_embedding, flow_strength=self.flow_strength)\n",
    "            # set any affinities of zero to a very small amount, to prevent the KL divergence from becoming infinite.\n",
    "            self.P_embedding_ts[i][self.P_embedding_ts[i] == 0] = self.epsilon # TODO: Perhaps enable later; this didn't cause NaN errors before\n",
    "            # self.P_embedding_ts[i] = self.P_embedding_ts[i] + self.epsilon\n",
    "        # take KL divergence between P embedding ts and P graph ts\n",
    "        diffusion_loss = 0\n",
    "        for i in range(len(self.ts)):\n",
    "            log_P_embedding_t = torch.log(self.P_embedding_ts[i])\n",
    "            if log_P_embedding_t.is_sparse:\n",
    "                diffusion_loss_for_t = self.KLD(log_P_embedding_t.to_dense(),self.P_graph_ts[i].to_dense())\n",
    "            else:\n",
    "                diffusion_loss_for_t = self.KLD(log_P_embedding_t,self.P_graph_ts[i])\n",
    "            diffusion_loss += (2**(-i))*diffusion_loss_for_t\n",
    "            # print(f\"Diffusion loss {i} is {diffusion_loss}\")\n",
    "        self.losses['diffusion'].append(diffusion_loss)\n",
    "        if diffusion_loss.isnan():\n",
    "            raise NotImplementedError\n",
    "        return diffusion_loss\n",
    "\n",
    "    def loss(self):\n",
    "        # embed points\n",
    "        self.embedded_points = self.embedder(self.X)\n",
    "        # compute diffusion loss on embedded points\n",
    "        if self.diffusion_loss != 0:\n",
    "            diffusion_loss = self.diffusion_loss()\n",
    "        else:\n",
    "            diffusion_loss = 0\n",
    "        # compute autoencoder loss\n",
    "        if self.decoder is not None:\n",
    "            X_reconstructed = self.decoder(self.embedded_points)\n",
    "            reconstruction_loss = self.MSE(X_reconstructed, self.X)\n",
    "            self.losses['reconstruction'].append(reconstruction_loss)\n",
    "        else:\n",
    "            reconstruction_loss = 0\n",
    "        # regularizations\n",
    "        if self.loss_weights['smoothness'] != 0:\n",
    "            smoothness_loss = smoothness_of_vector_field(self.embedded_points,self.FlowArtist,device=self.device,grid_width=20)\n",
    "            self.losses['smoothness'].append(smoothness_loss)\n",
    "        else:\n",
    "            smoothness_loss = 0\n",
    "\n",
    "        if self.loss_weights['diffusion map regularization'] != 0:\n",
    "            diffmap_loss = diffusion_map_loss(self.P_graph_ts[0], self.embedded_points)\n",
    "            self.losses['diffusion map regularization'].append(diffmap_loss)\n",
    "        else:\n",
    "            diffmap_loss = 0\n",
    "\n",
    "        if self.loss_weights['flow cosine loss'] != 0:\n",
    "            flow_loss = flow_cosine_loss(self.embedded_points, self.ground_truth_flows, self.FlowArtist(self.embedded_points))\n",
    "            self.losses['flow cosine loss'].append(smoothness_loss)\n",
    "        else:\n",
    "            flow_loss = 0\n",
    "\n",
    "        cost = self.loss_weights['diffusion']*diffusion_loss \n",
    "        + self.loss_weights['reconstruction']*reconstruction_loss \n",
    "        + self.loss_weights['smoothness']*smoothness_loss\n",
    "        + self.loss_weights['diffusion map regularization']*diffmap_loss\n",
    "        + self.loss_weights['flow cosine loss']*flow_loss\n",
    "        return cost\n",
    "\n",
    "    def visualize_points(self, labels = None):\n",
    "        # controls the x and y axes of the plot\n",
    "        # linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)\n",
    "        if labels is None:\n",
    "            labels = self.labels\n",
    "        uv = self.FlowArtist(self.grid).detach().cpu()\n",
    "        u = uv[:,0].cpu()\n",
    "        v = uv[:,1].cpu()\n",
    "        x = self.grid.detach().cpu()[:,0]\n",
    "        y = self.grid.detach().cpu()[:,1]\n",
    "        # quiver \n",
    "        #   plots a 2D field of arrows\n",
    "        #   quiver([X, Y], U, V, [C], **kw); \n",
    "        #   X, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.\n",
    "        if labels is not None:\n",
    "            sc = plt.scatter(self.embedded_points[:,0].detach().cpu(),self.embedded_points[:,1].detach().cpu(), c=labels)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            sc = plt.scatter(self.embedded_points[:,0].detach().cpu(),self.embedded_points[:,1].detach().cpu())\n",
    "        plt.suptitle(\"Flow Embedding\")\n",
    "        plt.quiver(x,y,u,v)\n",
    "        # Display all open figures.\n",
    "        plt.show()\n",
    "\n",
    "  \n",
    "    def visualize_loss(self, loss_type = \"total\"):\n",
    "        # diffusion_loss,reconstruction_loss, smoothness_loss\n",
    "        x = []\n",
    "        k = \"\"\n",
    "        losses = {}\n",
    "        for key in self.losses.keys():\n",
    "            losses[key] = []\n",
    "            k = key\n",
    "        losses[\"total\"] = []\n",
    "        for i in range(len(self.losses[\"diffusion\"])):\n",
    "            x.append(i)\n",
    "            for key in self.losses.keys():\n",
    "                try:\n",
    "                    losses[key].append(self.losses[key][i].detach().cpu().numpy())\n",
    "                except:\n",
    "                    losses[key].append(0)\n",
    "        if loss_type == \"all\":\n",
    "            for key in self.losses.keys():\n",
    "                plt.plot(x, losses[key])\n",
    "            plt.legend(self.losses.keys(), loc='upper right')\n",
    "            plt.title(\"loss\")\n",
    "        else:\n",
    "            plt.plot(x, losses[loss_type])\n",
    "            plt.title(loss_type)\n",
    "\n",
    "    def visualize_diffusion_matrices(self):\n",
    "        fig, axs = plt.subplots(3,2, figsize=(10,15))\n",
    "        axs[0][0].set_title(f\"Ambient $P^{self.ts[0]}$\")\n",
    "        axs[0][0].imshow(self.P_graph_ts[0].detach().cpu().numpy())\n",
    "        axs[0][1].set_title(f\"Embedding $P^{self.ts[0]}$\")\n",
    "        axs[0][1].imshow(self.P_embedding_ts[0].detach().cpu().numpy())\n",
    "\n",
    "        axs[1][0].set_title(f\"Ambient $P^{self.ts[1]}$\")\n",
    "        axs[1][0].imshow(self.P_graph_ts[1].detach().cpu().numpy())\n",
    "        axs[1][1].set_title(f\"Embedding $P^{self.ts[1]}$\")\n",
    "        axs[1][1].imshow(self.P_embedding_ts[1].detach().cpu().numpy())\n",
    "\n",
    "        axs[2][0].set_title(f\"Ambient $P^{self.ts[2]}$\")\n",
    "        axs[2][0].imshow(self.P_graph_ts[2].detach().cpu().numpy())\n",
    "        axs[2][1].set_title(f\"Embedding $P^{self.ts[2]}$\")\n",
    "        axs[2][1].imshow(self.P_embedding_ts[2].detach().cpu().numpy())\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def fit(self,n_steps = 1000):\n",
    "        # train Flow Embedder on the provided graph\n",
    "        self.train()\n",
    "        # self.weight_of_flow = 0\n",
    "        for step in trange(n_steps):\n",
    "            # if step == 100:\n",
    "            # \tself.weight_of_flow = 1\n",
    "            # if step == 200:\n",
    "            # \tself.weight_of_flow = 0.5\n",
    "            self.optim.zero_grad()\n",
    "            # compute loss\n",
    "            loss = self.loss()\n",
    "            if loss.isnan():\n",
    "                print(\"Final loss was nan\")\n",
    "                raise NotImplementedError\n",
    "            # print(\"loss is \",loss)\n",
    "            # compute gradient and step backwards\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            if step % 500 == 0:\n",
    "                print(f\"EPOCH {step}. Loss {loss}. Flow strength {self.flow_strength}. Heatmap of P embedding is \")\n",
    "                self.visualize_diffusion_matrices()\n",
    "                self.visualize_points()\n",
    "            # TODO: Criteria to automatically end training\n",
    "        print(\"Exiting training with loss \",loss)\n",
    "        return self.embedded_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9ca80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from directed_graphs.datasets import directed_swiss_roll\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6941c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, flow, labels = directed_swiss_roll()\n",
    "lw = {\"diffusion\":1,\"smoothness\":0,\"reconstruction\":0,\"diffusion map regularization\":0,\"flow cosine loss\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecba37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X)\n",
    "flow = torch.tensor(flow)\n",
    "X = X.float().to(device)\n",
    "flow = flow.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFE = MultiscaleDiffusionFlowEmbedder(X, flow, device=device, loss_weights=lw).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFE.fit(n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MFE.visualize_points(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232df2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\"\"\"\n",
    "\t\tfor i in range(len(self.ts)):\n",
    "\t\t\tlog_P_embedding_t = torch.log(self.P_embedding_ts[i])\n",
    "\t\t\tlog_P_graph_t = torch.log(self.P_graph_ts[i])            \n",
    "\t\t\tif log_P_embedding_t.is_sparse:\n",
    "\t\t\t\tKL_emb = log_P_embedding_t.to_dense()\n",
    "\t\t\t\tKL_graph = log_P_graph_t.to_dense()\n",
    "\t\t\t\tdiffusion_loss_for_t = 0.5*(self.KLD(KL_emb, KL_graph) + self.KLD(KL_graph, KL_emb))\n",
    "\t\t\telse:\n",
    "\t\t\t\tA = log_P_embedding_t\n",
    "\t\t\t\tB = log_P_graph_t\n",
    "\t\t\t\tdiffusion_loss_for_t = 0.5*(self.KLD(A,B) + self.KLD(B,A))\n",
    "\t\t\tdiffusion_loss += (2**(-i))*diffusion_loss_for_t\n",
    "\t\t\t# print(f\"Diffusion loss {i} is {diffusion_loss}\")\n",
    "\t\t\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

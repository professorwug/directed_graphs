{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6431d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from tqdm import trange\n",
    "from directed_graphs.utils import diffusion_matrix_from_graph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from directed_graphs.diffusion_flow_embedding import affinity_matrix_from_pointset_to_pointset\n",
    "\n",
    "class DiffusionFlowEmbedder(torch.nn.Module):\n",
    "\tdef __init__(self, X, flows, t = 4, sigma_graph = 0.5, sigma_embedding=0.5, embedding_dimension=2):\n",
    "\t\t\"\"\"Flow Embedding with diffusion\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tX : torch tensor n_points x n_dim\n",
    "\t\t\tdata matrix\n",
    "\t\tflows : torch tensor n_points x n_dim\n",
    "\t\t\tThe flow at each point\n",
    "\t\tt : int\n",
    "\t\t\tLoss is computed with the diffusion operator powered to this number\n",
    "\t\tsigma in [0,1]\n",
    "\t\t\tKernel bandwidth in the embedding\n",
    "\t\t\"\"\"\n",
    "\t\t# initialize parameters\n",
    "\t\tsuper(DiffusionFlowEmbedder, self).__init__()\n",
    "\t\tself.X = X\n",
    "\t\tself.ground_truth_flows = flows\n",
    "\t\tself.t = t\n",
    "\t\tself.sigma_embedding = sigma_embedding\n",
    "\t\tself.sigma_graph = sigma_graph\n",
    "\t\tself.nnodes = X.shape[0]\n",
    "\t\tself.data_dimension = X.shape[1]\n",
    "\t\tself.losses = []\n",
    "\t\tself.embedding_dimension = embedding_dimension\n",
    "\t\t# Compute P^t of the graph, the powered diffusion matrix\n",
    "\t\t# TODO: This can be optimized using landmarks, etc. For now it's straight sparse matrix multiplication\n",
    "\t\t# TODO: Migrate to a specialized function for dataset affinity calculation, with automatic kernel bandwidth selection, and the like\n",
    "\t\tself.P_graph = affinity_matrix_from_pointset_to_pointset(X,X,flows,sigma=sigma_graph)\n",
    "\t\tself.P_graph_t = torch.matrix_power(self.P_graph,self.t)\n",
    "\t\t# Flow field\n",
    "\t\tself.FlowArtist = nn.Sequential(nn.Linear(2, 10),\n",
    "\t\t                       nn.Tanh(),\n",
    "\t\t                       nn.Linear(10, 10),\n",
    "\t\t                       nn.Tanh(),\n",
    "\t\t                       nn.Linear(10, 2))\n",
    "\t\t# Autoencoder to embed the points into a low dimension\n",
    "\t\tself.encoder = nn.Sequential(nn.Linear(self.data_dimension, 100),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(100, 10),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(10, self.embedding_dimension))\n",
    "\t\tself.decoder = nn.Sequential(nn.Linear(self.embedding_dimension, 10),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(10, 100),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnn.Linear(100, self.data_dimension))\n",
    "\t\t# training ops\n",
    "\t\tself.KLD = nn.KLDivLoss(reduction='batchmean',log_target=False)\n",
    "\t\tself.MSE = nn.MSELoss()\n",
    "\t\tself.optim = torch.optim.Adam(self.parameters())\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\n",
    "\tdef compute_embedding_P(self):\n",
    "\t\tA = affinity_matrix_from_pointset_to_pointset(self.embedded_points,self.embedded_points,flows = self.FlowArtist(self.embedded_points), sigma = self.sigma_embedding)\n",
    "\t\t# flow\n",
    "\t\tself.P_embedding = torch.diag(1/A.sum(axis=1)) @ A\n",
    "\t\t# power it\n",
    "\t\tself.P_embedding_t = torch.matrix_power(self.P_embedding,self.t)\n",
    "\n",
    "\tdef loss(self):\n",
    "\t\tself.embedded_points = self.encoder(self.X)\n",
    "\t\t# compute embedding diffusion matrix\n",
    "\t\tself.compute_embedding_P()\n",
    "\t\t# compute autoencoder loss\n",
    "\t\tX_reconstructed = self.decoder(self.embedded_points)\n",
    "\t\treconstruction_loss = self.MSE(X_reconstructed, self.X)\n",
    "\t\t# take KL divergence between it and actual P\n",
    "\t\tlog_P_embedding_t = torch.log(self.P_embedding_t)\n",
    "\t\tdiffusion_loss = self.KLD(log_P_embedding_t,self.P_graph_t)\n",
    "\t\tcost = diffusion_loss + reconstruction_loss\n",
    "\t\t# print(f\"cost is KLD {diffusion_loss} with recon {reconstruction_loss}\")\n",
    "\t\tself.losses.append([diffusion_loss,reconstruction_loss])\n",
    "\t\treturn cost\n",
    "\n",
    "\tdef visualize_points(self, labels):\n",
    "\t\t# controls the x and y axes of the plot\n",
    "\t\t# linspace(min on axis, max on axis, spacing on plot -- large number = more field arrows)\n",
    "\t\tminx = min(self.embedded_points[:,0].detach().cpu().numpy())-1\n",
    "\t\tmaxx = max(self.embedded_points[:,0].detach().cpu().numpy())+1\n",
    "\t\tminy = min(self.embedded_points[:,1].detach().cpu().numpy())-1\n",
    "\t\tmaxy = max(self.embedded_points[:,1].detach().cpu().numpy())+1\n",
    "\t\tx, y = np.meshgrid(np.linspace(minx,maxx,20),np.linspace(miny,maxy,20))\n",
    "\t\tx = torch.tensor(x,dtype=float).cpu()\n",
    "\t\ty = torch.tensor(y,dtype=float).cpu()\n",
    "\t\txy_t = torch.concat([x[:,:,None],y[:,:,None]],dim=2).float().to('cuda')\n",
    "\t\tuv = self.FlowArtist(xy_t).detach()\n",
    "\t\tu = uv[:,:,0].cpu()\n",
    "\t\tv = uv[:,:,1].cpu()\n",
    "\t\t\n",
    "\n",
    "\t\t# quiver \n",
    "\t\t# \tplots a 2D field of arrows\n",
    "\t\t# \tquiver([X, Y], U, V, [C], **kw); \n",
    "\t\t# \tX, Y define the arrow locations, U, V define the arrow directions, and C optionally sets the color.\n",
    "\t\t\n",
    "\t\tsc = plt.scatter(self.embedded_points[:,0].detach().cpu(),self.embedded_points[:,1].detach().cpu(), c=labels)\n",
    "\t\tplt.quiver(x,y,u,v)\n",
    "\t\tplt.legend()\n",
    "\t\t# Display all open figures.\n",
    "\t\tplt.show()\n",
    "\n",
    "\n",
    "\tdef fit(self,n_steps = 1000):\n",
    "\t\t# train Flow Embedder on the provided graph\n",
    "\t\tself.train()\n",
    "\t\tfor step in trange(n_steps):\n",
    "\t\t\tself.optim.zero_grad()\n",
    "\t\t\t# compute loss\n",
    "\t\t\tloss = self.loss()\n",
    "\t\t\t# print(\"loss is \",loss)\n",
    "\t\t\t# compute gradient and step backwards\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optim.step()\n",
    "\t\t\t# TODO: Criteria to automatically end training\n",
    "\t\tprint(\"Exiting training with loss \",loss)\n",
    "\t\treturn self.embedded_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166568db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.__version__[:4] == \"1.13\":\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.has_mps else 'cpu')\n",
    "else:\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ba66f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
